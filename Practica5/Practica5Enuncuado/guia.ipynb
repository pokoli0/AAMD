{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "060c0eca",
   "metadata": {},
   "source": [
    "# Guia para hacer un modelo de ia del examen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799919a5",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Limpiar los datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b4536",
   "metadata": {},
   "source": [
    "### QUITANDO FILAS Y COLUMNAS Y NORMALIZANDO DATOS\n",
    "\n",
    "Para normalizar los datos hay que tener en cuenta que:\n",
    "    \n",
    "    Discretos/Enumerados/Cualitativos -> OneHotEncoding o Labled Encoder\n",
    "        OneHotEncoding -> por defecto, si dudas usa este\n",
    "        LabledEncoder -> si los valores tienen un orden\n",
    "\n",
    "    Continuos -> StandardScaling, para normalizarlos y llevarlos a una escala comun\n",
    "\n",
    "\n",
    "\n",
    "    -> solo deberia hacer falta copiar este codigo y cambiar las columnas en ATRIBUTOS, en final_data salen todos los datos sin el atributo solucion y en labeled_data el solucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d3a95d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import glob as glob\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "# ---------------------------- / LECTURA DE DATOS / ----------------------------------\n",
    "data = pd.read_csv(\"dementia_dataset.csv\") \n",
    "\n",
    "\n",
    "\n",
    "# --------------- / ATRIBUTOS / ---------------------\n",
    "unnecessary_columns = [\n",
    "    \"Subject ID\", \n",
    "    \"MRI ID\", \n",
    "    \"Hand\"          #\n",
    "    ]\n",
    "oneHot_columns = [\n",
    "    \"M/F\"\n",
    "    ]\n",
    "standardScaling_columns = [\n",
    "    \"EDUC\",\n",
    "    \"SES\",\n",
    "    \"MMSE\",\n",
    "    \"CDR\",\n",
    "    \"eTIV\",\n",
    "    \"nWBV\",\n",
    "    \"ASF\",\n",
    "    \"Visit\",        #\n",
    "    \"MR Delay\"\n",
    "]\n",
    "labeled_columns = [         # en este caso solo hay una columna que queramos, como es la solucion la codificamos por separado\n",
    "    \"Group\"\n",
    "    ]  \n",
    "solucion = \"Group\"\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / DROP /  -------------------\n",
    "# pandas tiene la opcion de quitar columnas segun sus nombres\n",
    "final_data = data.drop(columns=unnecessary_columns) \n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / OHE /  -------------------\n",
    "encoder = OneHotEncoder(sparse_output=False) \n",
    "encoder_final = encoder.fit_transform(data[oneHot_columns])  \n",
    "oneHot_df = pd.DataFrame(encoder_final, columns=encoder.get_feature_names_out(oneHot_columns))\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / SS /  -------------------\n",
    "scaler = StandardScaler()\n",
    "scaler_final = scaler.fit_transform(data[standardScaling_columns])\n",
    "df_sc = pd.DataFrame(scaler_final, columns=standardScaling_columns, index=data.index)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- / LABELED ENCODER / -------------------------   \n",
    "labler = LabelEncoder()\n",
    "labeled_final = labler.fit_transform(data[labeled_columns])\n",
    "df_lbl = pd.DataFrame(labeled_final, columns=labeled_columns, index=data.index)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# junta el df sin las columnas del oneHot con las del oneHot en el eje de columnas\n",
    "final_data = pd.concat([df_sc, oneHot_df], axis=1)\n",
    "final_data = pd.concat([final_data, df_lbl], axis=1)\n",
    "\n",
    "# quita los NaN\n",
    "final_data = final_data.dropna(how=\"any\")\n",
    "\n",
    "# los separa\n",
    "labeled_data = final_data[solucion]\n",
    "final_data = final_data.drop(columns=[solucion]) \n",
    "\n",
    "# para guardarlas en un archivo (opcional)\n",
    "#final_data.to_csv(\"./examen.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5dcc29",
   "metadata": {},
   "source": [
    "#### Slices en Python (resumen rapido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d9b079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "start = 0\n",
    "stop = 2\n",
    "step = 1\n",
    "\n",
    "a[start:stop]  # items start through stop-1\n",
    "a[start:]      # items start through the rest of the array\n",
    "a[:stop]       # items from the beginning through stop-1\n",
    "a[:]           # a copy of the whole array\n",
    "\n",
    "# ---------------------------------------------\n",
    "\n",
    "a[start:stop:step] # start through not past stop, by step\n",
    "\n",
    "# ---------------------------------------------\n",
    "\n",
    "a[-1]    # last item in the array\n",
    "a[-2:]   # last two items in the array\n",
    "a[:-2]   # everything except the last two items\n",
    "\n",
    "# ---------------------------------------------\n",
    "\n",
    "a[::-1]    # all items in the array, reversed\n",
    "a[1::-1]   # the first two items, reversed\n",
    "a[:-3:-1]  # the last two items, reversed\n",
    "a[-3::-1]  # everything except the last two items, reversed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a2ba7",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Representar los datos\n",
    "(WIP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e059d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Group'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Group'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     16\u001b[39m clase = solucion\n\u001b[32m     17\u001b[39m df_pca = pd.DataFrame({\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mc1\u001b[39m\u001b[33m\"\u001b[39m: x_pca[:, \u001b[32m0\u001b[39m],    \u001b[38;5;66;03m# atributo 1\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mc2\u001b[39m\u001b[33m\"\u001b[39m: x_pca[:, \u001b[32m1\u001b[39m],    \u001b[38;5;66;03m# atributo 2\u001b[39;00m\n\u001b[32m     20\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m grupos = \u001b[38;5;28msorted\u001b[39m(\u001b[43mdf_pca\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclase\u001b[49m\u001b[43m]\u001b[49m.unique())\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# colores\u001b[39;00m\n\u001b[32m     24\u001b[39m colormap = plt.colormaps.get_cmap(\u001b[33m\"\u001b[39m\u001b[33mviridis\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Group'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# -------------------- / FILTRADO DE DATOS / -------------------\n",
    "x = final_data\n",
    "y = labeled_data\n",
    "\n",
    "color = y  #codificando cada action como un color\n",
    "\n",
    "# ------------------- / DISMINUCION DE DIMENSIONES / ------------------------ \n",
    "pca_comp = PCA(n_components=2)\n",
    "x_pca = pca_comp.fit_transform(x)\n",
    "\n",
    "clase = solucion\n",
    "df_pca = pd.DataFrame({\n",
    "    \"c1\": x_pca[:, 0],    # atributo 1\n",
    "    \"c2\": x_pca[:, 1],    # atributo 2\n",
    "    clase: y\n",
    "})\n",
    "grupos = sorted(df_pca[clase].unique())\n",
    "\n",
    "# colores\n",
    "colormap = plt.colormaps.get_cmap(\"viridis\")\n",
    "colors = colormap(np.linspace(0, 1, len(grupos)))   # tantos colores como clases haya\n",
    "\n",
    "\n",
    "# ---------------------------- / PINTADO / ------------------------ \n",
    "\n",
    "# dibujado\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, g in enumerate(grupos):\n",
    "    # para pintar cada posible solucion\n",
    "    subset = df_pca[df_pca[clase] == g]\n",
    "    plt.scatter(\n",
    "        subset[\"c1\"], \n",
    "        subset[\"c2\"],\n",
    "        c = colors[i],\n",
    "        alpha = 0.7\n",
    "        )\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79fde29",
   "metadata": {},
   "source": [
    "## Ejercicio 3: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e27c595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MLP_Complete as mlp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final_data.values\n",
    "y = labeled_data.values\n",
    "\n",
    "# separa los datos \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# codificamos la 'solucion' (de labeled a ohe)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488ea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration      1: Cost   2.0169   \n",
      "Iteration    101: Cost   1.6673   \n",
      "Iteration    201: Cost   1.6602   \n",
      "Iteration    301: Cost   1.1340   \n",
      "Iteration    401: Cost   0.6116   \n",
      "Iteration    501: Cost   0.5946   \n",
      "Iteration    601: Cost   0.5769   \n",
      "Iteration    701: Cost   0.5559   \n",
      "Iteration    801: Cost   0.5336   \n",
      "Iteration    901: Cost   0.5098   \n",
      "Iteration   1001: Cost   0.4803   \n",
      "Iteration   1101: Cost   0.4454   \n",
      "Iteration   1201: Cost   0.4155   \n",
      "Iteration   1301: Cost   0.3959   \n",
      "Iteration   1401: Cost   0.4136   \n",
      "Iteration   1501: Cost   0.3841   \n",
      "Iteration   1601: Cost   0.3748   \n",
      "Iteration   1701: Cost   0.3661   \n",
      "Iteration   1801: Cost   0.3563   \n",
      "Iteration   1901: Cost   0.3453   \n",
      "Iteration   2000: Cost   0.3337   \n",
      "-> Validacion Custom MLP: 85.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x23ef8bd29e0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# valores que vamos tocando\n",
    "LAYERS=(128, 64, 32)\n",
    "LAMBDA=0.001\n",
    "LR_INIT=0.5\n",
    "ITERATIONS=2000\n",
    "\n",
    "# mlp\n",
    "mlp_custom = mlp.MLP_Complete(inputLayer=X_train.shape[1], \n",
    "                              hiddenLayers=list(LAYERS), \n",
    "                              outputLayer=y_train_encoded.shape[1], \n",
    "                              seed=42)\n",
    "\n",
    "mlp_custom.backpropagation(X_train, \n",
    "                        y_train_encoded, \n",
    "                        alpha=LR_INIT, \n",
    "                        lambda_=LAMBDA, \n",
    "                        numIte=ITERATIONS, \n",
    "                        verbose=100)\n",
    "\n",
    "a, z = mlp_custom.feedforward(X_test)\n",
    "y_pred = mlp_custom.predict(a[-1])\n",
    "    \n",
    "\n",
    "\n",
    "# resultados\n",
    "acc_custom = accuracy_score(y_test, y_pred)\n",
    "print(f\"-> Validacion Custom MLP: {acc_custom * 100:.2f}%\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap=\"Reds\", colorbar=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92073f",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Otros modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac748f5",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "   | pros | cons | \n",
    "   |---|---|\n",
    "   | tolerancia a ruido | caja negra |\n",
    "   | lineal y no lineal | costoso |\n",
    "   | escalable | --- |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "386d3231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.32073173\n",
      "Iteration 2, loss = 3.96235383\n",
      "Iteration 3, loss = 1.06117503\n",
      "Iteration 4, loss = 0.95524426\n",
      "Iteration 5, loss = 0.92094986\n",
      "Iteration 6, loss = 0.91462271\n",
      "Iteration 7, loss = 0.91362414\n",
      "Iteration 8, loss = 0.90979727\n",
      "Iteration 9, loss = 0.89987311\n",
      "Iteration 10, loss = 0.88481297\n",
      "Iteration 11, loss = 0.86890031\n",
      "Iteration 12, loss = 0.85230531\n",
      "Iteration 13, loss = 0.82924883\n",
      "Iteration 14, loss = 0.79212821\n",
      "Iteration 15, loss = 0.74353883\n",
      "Iteration 16, loss = 0.68592702\n",
      "Iteration 17, loss = 0.62014524\n",
      "Iteration 18, loss = 0.55900670\n",
      "Iteration 19, loss = 0.50809611\n",
      "Iteration 20, loss = 0.46957015\n",
      "Iteration 21, loss = 0.42800797\n",
      "Iteration 22, loss = 0.39524042\n",
      "Iteration 23, loss = 0.36952226\n",
      "Iteration 24, loss = 0.34923137\n",
      "Iteration 25, loss = 0.33342985\n",
      "Iteration 26, loss = 0.32230274\n",
      "Iteration 27, loss = 0.31337895\n",
      "Iteration 28, loss = 0.30889045\n",
      "Iteration 29, loss = 0.30471847\n",
      "Iteration 30, loss = 0.30065784\n",
      "Iteration 31, loss = 0.29839316\n",
      "Iteration 32, loss = 0.29544874\n",
      "Iteration 33, loss = 0.29029793\n",
      "Iteration 34, loss = 0.28806548\n",
      "Iteration 35, loss = 0.28565497\n",
      "Iteration 36, loss = 0.28595345\n",
      "Iteration 37, loss = 0.28424777\n",
      "Iteration 38, loss = 0.28189149\n",
      "Iteration 39, loss = 0.28107616\n",
      "Iteration 40, loss = 0.27930201\n",
      "Iteration 41, loss = 0.27621990\n",
      "Iteration 42, loss = 0.27653241\n",
      "Iteration 43, loss = 0.27461965\n",
      "Iteration 44, loss = 0.27355261\n",
      "Iteration 45, loss = 0.27622640\n",
      "Iteration 46, loss = 0.27621798\n",
      "Iteration 47, loss = 0.26793578\n",
      "Iteration 48, loss = 0.26925136\n",
      "Iteration 49, loss = 0.27338925\n",
      "Iteration 50, loss = 0.27028154\n",
      "Iteration 51, loss = 0.26312146\n",
      "Iteration 52, loss = 0.26243949\n",
      "Iteration 53, loss = 0.25895317\n",
      "Iteration 54, loss = 0.25811776\n",
      "Iteration 55, loss = 0.26255922\n",
      "Iteration 56, loss = 0.25261525\n",
      "Iteration 57, loss = 0.25156577\n",
      "Iteration 58, loss = 0.25356079\n",
      "Iteration 59, loss = 0.24988685\n",
      "Iteration 60, loss = 0.24226292\n",
      "Iteration 61, loss = 0.24237217\n",
      "Iteration 62, loss = 0.24327172\n",
      "Iteration 63, loss = 0.23450708\n",
      "Iteration 64, loss = 0.23138633\n",
      "Iteration 65, loss = 0.22821137\n",
      "Iteration 66, loss = 0.22920002\n",
      "Iteration 67, loss = 0.22942668\n",
      "Iteration 68, loss = 0.22357850\n",
      "Iteration 69, loss = 0.22220435\n",
      "Iteration 70, loss = 0.21810857\n",
      "Iteration 71, loss = 0.21703944\n",
      "Iteration 72, loss = 0.21555242\n",
      "Iteration 73, loss = 0.21345340\n",
      "Iteration 74, loss = 0.21293916\n",
      "Iteration 75, loss = 0.21283354\n",
      "Iteration 76, loss = 0.21113256\n",
      "Iteration 77, loss = 0.21019635\n",
      "Iteration 78, loss = 0.20949227\n",
      "Iteration 79, loss = 0.20804890\n",
      "Iteration 80, loss = 0.20648425\n",
      "Iteration 81, loss = 0.20701408\n",
      "Iteration 82, loss = 0.20495015\n",
      "Iteration 83, loss = 0.20665891\n",
      "Iteration 84, loss = 0.20309110\n",
      "Iteration 85, loss = 0.20451682\n",
      "Iteration 86, loss = 0.20295533\n",
      "Iteration 87, loss = 0.20243364\n",
      "Iteration 88, loss = 0.20278885\n",
      "Iteration 89, loss = 0.20655676\n",
      "Iteration 90, loss = 0.20800017\n",
      "Iteration 91, loss = 0.20673172\n",
      "Iteration 92, loss = 0.20605346\n",
      "Iteration 93, loss = 0.19982320\n",
      "Iteration 94, loss = 0.20350964\n",
      "Iteration 95, loss = 0.19968253\n",
      "Iteration 96, loss = 0.20089288\n",
      "Iteration 97, loss = 0.20088435\n",
      "Iteration 98, loss = 0.20023837\n",
      "Iteration 99, loss = 0.19696032\n",
      "Iteration 100, loss = 0.19914631\n",
      "Iteration 101, loss = 0.19807777\n",
      "Iteration 102, loss = 0.19836872\n",
      "Iteration 103, loss = 0.20171834\n",
      "Iteration 104, loss = 0.19988985\n",
      "Iteration 105, loss = 0.19954903\n",
      "Iteration 106, loss = 0.19753199\n",
      "Iteration 107, loss = 0.19820001\n",
      "Iteration 108, loss = 0.19816622\n",
      "Iteration 109, loss = 0.20156711\n",
      "Iteration 110, loss = 0.19706376\n",
      "Iteration 111, loss = 0.19545915\n",
      "Iteration 112, loss = 0.19699601\n",
      "Iteration 113, loss = 0.19844629\n",
      "Iteration 114, loss = 0.20476454\n",
      "Iteration 115, loss = 0.19648904\n",
      "Iteration 116, loss = 0.19800372\n",
      "Iteration 117, loss = 0.19611206\n",
      "Iteration 118, loss = 0.19624736\n",
      "Iteration 119, loss = 0.19312624\n",
      "Iteration 120, loss = 0.19332734\n",
      "Iteration 121, loss = 0.19394637\n",
      "Iteration 122, loss = 0.19797554\n",
      "Iteration 123, loss = 0.19138086\n",
      "Iteration 124, loss = 0.19195543\n",
      "Iteration 125, loss = 0.19405554\n",
      "Iteration 126, loss = 0.19440820\n",
      "Iteration 127, loss = 0.19038405\n",
      "Iteration 128, loss = 0.19275490\n",
      "Iteration 129, loss = 0.19489999\n",
      "Iteration 130, loss = 0.18983126\n",
      "Iteration 131, loss = 0.18920793\n",
      "Iteration 132, loss = 0.18920727\n",
      "Iteration 133, loss = 0.18934856\n",
      "Iteration 134, loss = 0.18955785\n",
      "Iteration 135, loss = 0.18803995\n",
      "Iteration 136, loss = 0.19002824\n",
      "Iteration 137, loss = 0.18888570\n",
      "Iteration 138, loss = 0.19263774\n",
      "Iteration 139, loss = 0.19549692\n",
      "Iteration 140, loss = 0.19847911\n",
      "Iteration 141, loss = 0.19392424\n",
      "Iteration 142, loss = 0.19293195\n",
      "Iteration 143, loss = 0.18952608\n",
      "Iteration 144, loss = 0.18814298\n",
      "Iteration 145, loss = 0.18647395\n",
      "Iteration 146, loss = 0.18844992\n",
      "Iteration 147, loss = 0.18904555\n",
      "Iteration 148, loss = 0.18869569\n",
      "Iteration 149, loss = 0.19082263\n",
      "Iteration 150, loss = 0.18631036\n",
      "Iteration 151, loss = 0.18895850\n",
      "Iteration 152, loss = 0.18605438\n",
      "Iteration 153, loss = 0.18660568\n",
      "Iteration 154, loss = 0.19081005\n",
      "Iteration 155, loss = 0.18942926\n",
      "Iteration 156, loss = 0.18477712\n",
      "Iteration 157, loss = 0.18645584\n",
      "Iteration 158, loss = 0.19105455\n",
      "Iteration 159, loss = 0.18904701\n",
      "Iteration 160, loss = 0.18431397\n",
      "Iteration 161, loss = 0.18292095\n",
      "Iteration 162, loss = 0.18474099\n",
      "Iteration 163, loss = 0.18612266\n",
      "Iteration 164, loss = 0.18455427\n",
      "Iteration 165, loss = 0.18433985\n",
      "Iteration 166, loss = 0.18183186\n",
      "Iteration 167, loss = 0.18373574\n",
      "Iteration 168, loss = 0.18081738\n",
      "Iteration 169, loss = 0.18301889\n",
      "Iteration 170, loss = 0.18238566\n",
      "Iteration 171, loss = 0.18293223\n",
      "Iteration 172, loss = 0.18077626\n",
      "Iteration 173, loss = 0.18475410\n",
      "Iteration 174, loss = 0.18591433\n",
      "Iteration 175, loss = 0.18096580\n",
      "Iteration 176, loss = 0.17828660\n",
      "Iteration 177, loss = 0.17870845\n",
      "Iteration 178, loss = 0.18198045\n",
      "Iteration 179, loss = 0.17909117\n",
      "Iteration 180, loss = 0.18145848\n",
      "Iteration 181, loss = 0.18217199\n",
      "Iteration 182, loss = 0.18112080\n",
      "Iteration 183, loss = 0.17997116\n",
      "Iteration 184, loss = 0.17748670\n",
      "Iteration 185, loss = 0.17814641\n",
      "Iteration 186, loss = 0.17884094\n",
      "Iteration 187, loss = 0.17890522\n",
      "Iteration 188, loss = 0.18791615\n",
      "Iteration 189, loss = 0.18850542\n",
      "Iteration 190, loss = 0.17477706\n",
      "Iteration 191, loss = 0.18882884\n",
      "Iteration 192, loss = 0.17803412\n",
      "Iteration 193, loss = 0.17951860\n",
      "Iteration 194, loss = 0.17923725\n",
      "Iteration 195, loss = 0.17303583\n",
      "Iteration 196, loss = 0.17571925\n",
      "Iteration 197, loss = 0.18057006\n",
      "Iteration 198, loss = 0.17322975\n",
      "Iteration 199, loss = 0.17803029\n",
      "Iteration 200, loss = 0.17307399\n",
      "Iteration 201, loss = 0.16952288\n",
      "Iteration 202, loss = 0.17410833\n",
      "Iteration 203, loss = 0.17408921\n",
      "Iteration 204, loss = 0.17347291\n",
      "Iteration 205, loss = 0.17252895\n",
      "Iteration 206, loss = 0.16835789\n",
      "Iteration 207, loss = 0.17467807\n",
      "Iteration 208, loss = 0.16728107\n",
      "Iteration 209, loss = 0.16586879\n",
      "Iteration 210, loss = 0.16883038\n",
      "Iteration 211, loss = 0.16588761\n",
      "Iteration 212, loss = 0.16494155\n",
      "Iteration 213, loss = 0.16682109\n",
      "Iteration 214, loss = 0.16731644\n",
      "Iteration 215, loss = 0.16132217\n",
      "Iteration 216, loss = 0.16155178\n",
      "Iteration 217, loss = 0.16101775\n",
      "Iteration 218, loss = 0.16201207\n",
      "Iteration 219, loss = 0.16417900\n",
      "Iteration 220, loss = 0.16010591\n",
      "Iteration 221, loss = 0.15743016\n",
      "Iteration 222, loss = 0.15600396\n",
      "Iteration 223, loss = 0.15878844\n",
      "Iteration 224, loss = 0.15785655\n",
      "Iteration 225, loss = 0.15430465\n",
      "Iteration 226, loss = 0.15470562\n",
      "Iteration 227, loss = 0.15467350\n",
      "Iteration 228, loss = 0.15467677\n",
      "Iteration 229, loss = 0.15659675\n",
      "Iteration 230, loss = 0.15026424\n",
      "Iteration 231, loss = 0.16390040\n",
      "Iteration 232, loss = 0.15097900\n",
      "Iteration 233, loss = 0.14995884\n",
      "Iteration 234, loss = 0.14799158\n",
      "Iteration 235, loss = 0.14555664\n",
      "Iteration 236, loss = 0.14374942\n",
      "Iteration 237, loss = 0.14551842\n",
      "Iteration 238, loss = 0.14919171\n",
      "Iteration 239, loss = 0.14516411\n",
      "Iteration 240, loss = 0.14408910\n",
      "Iteration 241, loss = 0.14072363\n",
      "Iteration 242, loss = 0.14774763\n",
      "Iteration 243, loss = 0.13848682\n",
      "Iteration 244, loss = 0.13687717\n",
      "Iteration 245, loss = 0.14148384\n",
      "Iteration 246, loss = 0.14025781\n",
      "Iteration 247, loss = 0.13641948\n",
      "Iteration 248, loss = 0.13344672\n",
      "Iteration 249, loss = 0.13079240\n",
      "Iteration 250, loss = 0.13000636\n",
      "Iteration 251, loss = 0.12930265\n",
      "Iteration 252, loss = 0.12939296\n",
      "Iteration 253, loss = 0.13304496\n",
      "Iteration 254, loss = 0.12974869\n",
      "Iteration 255, loss = 0.12780408\n",
      "Iteration 256, loss = 0.12648048\n",
      "Iteration 257, loss = 0.12947836\n",
      "Iteration 258, loss = 0.12176704\n",
      "Iteration 259, loss = 0.12451615\n",
      "Iteration 260, loss = 0.11913994\n",
      "Iteration 261, loss = 0.12124386\n",
      "Iteration 262, loss = 0.11785201\n",
      "Iteration 263, loss = 0.11603960\n",
      "Iteration 264, loss = 0.11520762\n",
      "Iteration 265, loss = 0.11595490\n",
      "Iteration 266, loss = 0.11782276\n",
      "Iteration 267, loss = 0.11851779\n",
      "Iteration 268, loss = 0.11169829\n",
      "Iteration 269, loss = 0.11741921\n",
      "Iteration 270, loss = 0.11630007\n",
      "Iteration 271, loss = 0.11147023\n",
      "Iteration 272, loss = 0.10719929\n",
      "Iteration 273, loss = 0.10595442\n",
      "Iteration 274, loss = 0.10604922\n",
      "Iteration 275, loss = 0.10562704\n",
      "Iteration 276, loss = 0.10687135\n",
      "Iteration 277, loss = 0.11255884\n",
      "Iteration 278, loss = 0.10076054\n",
      "Iteration 279, loss = 0.10264094\n",
      "Iteration 280, loss = 0.09999818\n",
      "Iteration 281, loss = 0.09918035\n",
      "Iteration 282, loss = 0.10574707\n",
      "Iteration 283, loss = 0.11266150\n",
      "Iteration 284, loss = 0.09719706\n",
      "Iteration 285, loss = 0.09529996\n",
      "Iteration 286, loss = 0.09650834\n",
      "Iteration 287, loss = 0.09611578\n",
      "Iteration 288, loss = 0.09289781\n",
      "Iteration 289, loss = 0.09395568\n",
      "Iteration 290, loss = 0.09095123\n",
      "Iteration 291, loss = 0.09212237\n",
      "Iteration 292, loss = 0.09314618\n",
      "Iteration 293, loss = 0.09757702\n",
      "Iteration 294, loss = 0.09385352\n",
      "Iteration 295, loss = 0.08838757\n",
      "Iteration 296, loss = 0.08802225\n",
      "Iteration 297, loss = 0.08693189\n",
      "Iteration 298, loss = 0.08488344\n",
      "Iteration 299, loss = 0.08442849\n",
      "Iteration 300, loss = 0.08475559\n",
      "Iteration 301, loss = 0.08630986\n",
      "Iteration 302, loss = 0.08394411\n",
      "Iteration 303, loss = 0.08459177\n",
      "Iteration 304, loss = 0.08434847\n",
      "Iteration 305, loss = 0.07894971\n",
      "Iteration 306, loss = 0.08090950\n",
      "Iteration 307, loss = 0.07747510\n",
      "Iteration 308, loss = 0.07802746\n",
      "Iteration 309, loss = 0.07741889\n",
      "Iteration 310, loss = 0.07645685\n",
      "Iteration 311, loss = 0.07463259\n",
      "Iteration 312, loss = 0.07898218\n",
      "Iteration 313, loss = 0.07638698\n",
      "Iteration 314, loss = 0.08019293\n",
      "Iteration 315, loss = 0.07573035\n",
      "Iteration 316, loss = 0.07130963\n",
      "Iteration 317, loss = 0.07008098\n",
      "Iteration 318, loss = 0.06821760\n",
      "Iteration 319, loss = 0.06812704\n",
      "Iteration 320, loss = 0.07103166\n",
      "Iteration 321, loss = 0.06870105\n",
      "Iteration 322, loss = 0.07377095\n",
      "Iteration 323, loss = 0.06710504\n",
      "Iteration 324, loss = 0.06874364\n",
      "Iteration 325, loss = 0.06627950\n",
      "Iteration 326, loss = 0.06818062\n",
      "Iteration 327, loss = 0.06741258\n",
      "Iteration 328, loss = 0.06706414\n",
      "Iteration 329, loss = 0.06288040\n",
      "Iteration 330, loss = 0.06656125\n",
      "Iteration 331, loss = 0.06060134\n",
      "Iteration 332, loss = 0.06277309\n",
      "Iteration 333, loss = 0.06829398\n",
      "Iteration 334, loss = 0.06551370\n",
      "Iteration 335, loss = 0.05731064\n",
      "Iteration 336, loss = 0.05686992\n",
      "Iteration 337, loss = 0.05758221\n",
      "Iteration 338, loss = 0.05558678\n",
      "Iteration 339, loss = 0.05522377\n",
      "Iteration 340, loss = 0.05482325\n",
      "Iteration 341, loss = 0.05469343\n",
      "Iteration 342, loss = 0.06143696\n",
      "Iteration 343, loss = 0.06337765\n",
      "Iteration 344, loss = 0.05280410\n",
      "Iteration 345, loss = 0.05314501\n",
      "Iteration 346, loss = 0.05106108\n",
      "Iteration 347, loss = 0.06010229\n",
      "Iteration 348, loss = 0.05824610\n",
      "Iteration 349, loss = 0.04707871\n",
      "Iteration 350, loss = 0.05351099\n",
      "Iteration 351, loss = 0.04640024\n",
      "Iteration 352, loss = 0.05051137\n",
      "Iteration 353, loss = 0.04830614\n",
      "Iteration 354, loss = 0.04555772\n",
      "Iteration 355, loss = 0.04432650\n",
      "Iteration 356, loss = 0.04323443\n",
      "Iteration 357, loss = 0.04361333\n",
      "Iteration 358, loss = 0.04281684\n",
      "Iteration 359, loss = 0.04224206\n",
      "Iteration 360, loss = 0.04119755\n",
      "Iteration 361, loss = 0.04164682\n",
      "Iteration 362, loss = 0.03968507\n",
      "Iteration 363, loss = 0.03957141\n",
      "Iteration 364, loss = 0.04042373\n",
      "Iteration 365, loss = 0.04024150\n",
      "Iteration 366, loss = 0.03923513\n",
      "Iteration 367, loss = 0.03794064\n",
      "Iteration 368, loss = 0.03770194\n",
      "Iteration 369, loss = 0.03750985\n",
      "Iteration 370, loss = 0.03601902\n",
      "Iteration 371, loss = 0.03875688\n",
      "Iteration 372, loss = 0.04393754\n",
      "Iteration 373, loss = 0.03464885\n",
      "Iteration 374, loss = 0.03540114\n",
      "Iteration 375, loss = 0.03530033\n",
      "Iteration 376, loss = 0.03560288\n",
      "Iteration 377, loss = 0.03544186\n",
      "Iteration 378, loss = 0.03176705\n",
      "Iteration 379, loss = 0.03153448\n",
      "Iteration 380, loss = 0.03133197\n",
      "Iteration 381, loss = 0.03241709\n",
      "Iteration 382, loss = 0.03416316\n",
      "Iteration 383, loss = 0.03741763\n",
      "Iteration 384, loss = 0.03516779\n",
      "Iteration 385, loss = 0.03840631\n",
      "Iteration 386, loss = 0.03122031\n",
      "Iteration 387, loss = 0.02907084\n",
      "Iteration 388, loss = 0.02859005\n",
      "Iteration 389, loss = 0.02878109\n",
      "Iteration 390, loss = 0.02871276\n",
      "Iteration 391, loss = 0.02722416\n",
      "Iteration 392, loss = 0.02668673\n",
      "Iteration 393, loss = 0.02656777\n",
      "Iteration 394, loss = 0.02623634\n",
      "Iteration 395, loss = 0.02907878\n",
      "Iteration 396, loss = 0.02804999\n",
      "Iteration 397, loss = 0.02548857\n",
      "Iteration 398, loss = 0.02664994\n",
      "Iteration 399, loss = 0.02849611\n",
      "Iteration 400, loss = 0.02588319\n",
      "Iteration 401, loss = 0.02761578\n",
      "Iteration 402, loss = 0.03757195\n",
      "Iteration 403, loss = 0.02401778\n",
      "Iteration 404, loss = 0.02305208\n",
      "Iteration 405, loss = 0.02246086\n",
      "Iteration 406, loss = 0.02263447\n",
      "Iteration 407, loss = 0.02381153\n",
      "Iteration 408, loss = 0.02777083\n",
      "Iteration 409, loss = 0.02246360\n",
      "Iteration 410, loss = 0.02208945\n",
      "Iteration 411, loss = 0.02251456\n",
      "Iteration 412, loss = 0.02280549\n",
      "Iteration 413, loss = 0.02404591\n",
      "Iteration 414, loss = 0.02199180\n",
      "Iteration 415, loss = 0.02587334\n",
      "Iteration 416, loss = 0.02202452\n",
      "Iteration 417, loss = 0.02227440\n",
      "Iteration 418, loss = 0.02019940\n",
      "Iteration 419, loss = 0.01920888\n",
      "Iteration 420, loss = 0.02019603\n",
      "Iteration 421, loss = 0.02321861\n",
      "Iteration 422, loss = 0.02104547\n",
      "Iteration 423, loss = 0.01927747\n",
      "Iteration 424, loss = 0.01844438\n",
      "Iteration 425, loss = 0.01805034\n",
      "Iteration 426, loss = 0.01862956\n",
      "Iteration 427, loss = 0.01864859\n",
      "Iteration 428, loss = 0.01799575\n",
      "Iteration 429, loss = 0.01883175\n",
      "Iteration 430, loss = 0.01969214\n",
      "Iteration 431, loss = 0.01779149\n",
      "Iteration 432, loss = 0.01716721\n",
      "Iteration 433, loss = 0.01791738\n",
      "Iteration 434, loss = 0.01785585\n",
      "Iteration 435, loss = 0.01747118\n",
      "Iteration 436, loss = 0.01727960\n",
      "Iteration 437, loss = 0.01651089\n",
      "Iteration 438, loss = 0.01602956\n",
      "Iteration 439, loss = 0.01747868\n",
      "Iteration 440, loss = 0.01982010\n",
      "Iteration 441, loss = 0.01597562\n",
      "Iteration 442, loss = 0.01541351\n",
      "Iteration 443, loss = 0.01550946\n",
      "Iteration 444, loss = 0.01572054\n",
      "Iteration 445, loss = 0.01637399\n",
      "Iteration 446, loss = 0.01634123\n",
      "Iteration 447, loss = 0.01498182\n",
      "Iteration 448, loss = 0.01553151\n",
      "Iteration 449, loss = 0.01578801\n",
      "Iteration 450, loss = 0.01598707\n",
      "Iteration 451, loss = 0.01570547\n",
      "Iteration 452, loss = 0.01410611\n",
      "Iteration 453, loss = 0.01456018\n",
      "Iteration 454, loss = 0.01412409\n",
      "Iteration 455, loss = 0.01373519\n",
      "Iteration 456, loss = 0.01374595\n",
      "Iteration 457, loss = 0.01414438\n",
      "Iteration 458, loss = 0.01407813\n",
      "Iteration 459, loss = 0.01425689\n",
      "Iteration 460, loss = 0.01393927\n",
      "Iteration 461, loss = 0.01420607\n",
      "Iteration 462, loss = 0.01418019\n",
      "Iteration 463, loss = 0.01329770\n",
      "Iteration 464, loss = 0.01427651\n",
      "Iteration 465, loss = 0.01470014\n",
      "Iteration 466, loss = 0.01414623\n",
      "Iteration 467, loss = 0.01433253\n",
      "Iteration 468, loss = 0.01259694\n",
      "Iteration 469, loss = 0.01263440\n",
      "Iteration 470, loss = 0.01233715\n",
      "Iteration 471, loss = 0.01267601\n",
      "Iteration 472, loss = 0.01365745\n",
      "Iteration 473, loss = 0.01283097\n",
      "Iteration 474, loss = 0.01223450\n",
      "Iteration 475, loss = 0.01309563\n",
      "Iteration 476, loss = 0.01173307\n",
      "Iteration 477, loss = 0.01230581\n",
      "Iteration 478, loss = 0.01157252\n",
      "Iteration 479, loss = 0.01158415\n",
      "Iteration 480, loss = 0.01153773\n",
      "Iteration 481, loss = 0.01135302\n",
      "Iteration 482, loss = 0.01149187\n",
      "Iteration 483, loss = 0.01118639\n",
      "Iteration 484, loss = 0.01120513\n",
      "Iteration 485, loss = 0.01114570\n",
      "Iteration 486, loss = 0.01094991\n",
      "Iteration 487, loss = 0.01089553\n",
      "Iteration 488, loss = 0.01099432\n",
      "Iteration 489, loss = 0.01126479\n",
      "Iteration 490, loss = 0.01096729\n",
      "Iteration 491, loss = 0.01057310\n",
      "Iteration 492, loss = 0.01092973\n",
      "Iteration 493, loss = 0.01047930\n",
      "Iteration 494, loss = 0.01087103\n",
      "Iteration 495, loss = 0.01076794\n",
      "Iteration 496, loss = 0.01037469\n",
      "Iteration 497, loss = 0.01021736\n",
      "Iteration 498, loss = 0.01058179\n",
      "Iteration 499, loss = 0.01119100\n",
      "Iteration 500, loss = 0.01013059\n",
      "Iteration 501, loss = 0.01048300\n",
      "Iteration 502, loss = 0.01107173\n",
      "Iteration 503, loss = 0.01090597\n",
      "Iteration 504, loss = 0.01121459\n",
      "Iteration 505, loss = 0.01034208\n",
      "Iteration 506, loss = 0.01005380\n",
      "Iteration 507, loss = 0.00992384\n",
      "Iteration 508, loss = 0.00970963\n",
      "Iteration 509, loss = 0.01044319\n",
      "Iteration 510, loss = 0.01080559\n",
      "Iteration 511, loss = 0.00989245\n",
      "Iteration 512, loss = 0.00997186\n",
      "Iteration 513, loss = 0.00994019\n",
      "Iteration 514, loss = 0.00932969\n",
      "Iteration 515, loss = 0.00947830\n",
      "Iteration 516, loss = 0.00984756\n",
      "Iteration 517, loss = 0.00928627\n",
      "Iteration 518, loss = 0.00915728\n",
      "Iteration 519, loss = 0.00937303\n",
      "Iteration 520, loss = 0.00981812\n",
      "Iteration 521, loss = 0.00922912\n",
      "Iteration 522, loss = 0.00905811\n",
      "Iteration 523, loss = 0.00910137\n",
      "Iteration 524, loss = 0.00918130\n",
      "Iteration 525, loss = 0.00893614\n",
      "Iteration 526, loss = 0.00913486\n",
      "Iteration 527, loss = 0.00877359\n",
      "Iteration 528, loss = 0.00891696\n",
      "Iteration 529, loss = 0.00884976\n",
      "Iteration 530, loss = 0.00921271\n",
      "Iteration 531, loss = 0.00869967\n",
      "Iteration 532, loss = 0.00866594\n",
      "Iteration 533, loss = 0.00890101\n",
      "Iteration 534, loss = 0.00859223\n",
      "Iteration 535, loss = 0.00857155\n",
      "Iteration 536, loss = 0.00845641\n",
      "Iteration 537, loss = 0.00846957\n",
      "Iteration 538, loss = 0.00861317\n",
      "Iteration 539, loss = 0.00860236\n",
      "Iteration 540, loss = 0.00869222\n",
      "Iteration 541, loss = 0.00838035\n",
      "Iteration 542, loss = 0.00843768\n",
      "Iteration 543, loss = 0.00835267\n",
      "Iteration 544, loss = 0.00843862\n",
      "Iteration 545, loss = 0.00841920\n",
      "Iteration 546, loss = 0.00831029\n",
      "Iteration 547, loss = 0.00882285\n",
      "Iteration 548, loss = 0.00883846\n",
      "Iteration 549, loss = 0.00858955\n",
      "Iteration 550, loss = 0.00835796\n",
      "Iteration 551, loss = 0.00811910\n",
      "Iteration 552, loss = 0.00815869\n",
      "Iteration 553, loss = 0.00803384\n",
      "Iteration 554, loss = 0.00821293\n",
      "Iteration 555, loss = 0.00824914\n",
      "Iteration 556, loss = 0.00836905\n",
      "Iteration 557, loss = 0.00804528\n",
      "Iteration 558, loss = 0.00798827\n",
      "Iteration 559, loss = 0.00787469\n",
      "Iteration 560, loss = 0.00798755\n",
      "Iteration 561, loss = 0.00805415\n",
      "Iteration 562, loss = 0.00817895\n",
      "Iteration 563, loss = 0.00808760\n",
      "Iteration 564, loss = 0.00780031\n",
      "Iteration 565, loss = 0.00771165\n",
      "Iteration 566, loss = 0.00775461\n",
      "Iteration 567, loss = 0.00769060\n",
      "Iteration 568, loss = 0.00765121\n",
      "Iteration 569, loss = 0.00772011\n",
      "Iteration 570, loss = 0.00771366\n",
      "Iteration 571, loss = 0.00759615\n",
      "Iteration 572, loss = 0.00778592\n",
      "Iteration 573, loss = 0.00777145\n",
      "Iteration 574, loss = 0.00782426\n",
      "Iteration 575, loss = 0.00748444\n",
      "Iteration 576, loss = 0.00757244\n",
      "Iteration 577, loss = 0.00752974\n",
      "Iteration 578, loss = 0.00746193\n",
      "Iteration 579, loss = 0.00748956\n",
      "Iteration 580, loss = 0.00757315\n",
      "Iteration 581, loss = 0.00751317\n",
      "Iteration 582, loss = 0.00756300\n",
      "Iteration 583, loss = 0.00759930\n",
      "Iteration 584, loss = 0.00767194\n",
      "Iteration 585, loss = 0.00739301\n",
      "Iteration 586, loss = 0.00728801\n",
      "Iteration 587, loss = 0.00732272\n",
      "Iteration 588, loss = 0.00732470\n",
      "Iteration 589, loss = 0.00733864\n",
      "Iteration 590, loss = 0.00720161\n",
      "Iteration 591, loss = 0.00728891\n",
      "Iteration 592, loss = 0.00733782\n",
      "Iteration 593, loss = 0.00731838\n",
      "Iteration 594, loss = 0.00721313\n",
      "Iteration 595, loss = 0.00713463\n",
      "Iteration 596, loss = 0.00725521\n",
      "Iteration 597, loss = 0.00724250\n",
      "Iteration 598, loss = 0.00713715\n",
      "Iteration 599, loss = 0.00710277\n",
      "Iteration 600, loss = 0.00711309\n",
      "Iteration 601, loss = 0.00717579\n",
      "Iteration 602, loss = 0.00705747\n",
      "Iteration 603, loss = 0.00717911\n",
      "Iteration 604, loss = 0.00717405\n",
      "Iteration 605, loss = 0.00700216\n",
      "Iteration 606, loss = 0.00732209\n",
      "Iteration 607, loss = 0.00738884\n",
      "Iteration 608, loss = 0.00691460\n",
      "Iteration 609, loss = 0.00745238\n",
      "Iteration 610, loss = 0.00690421\n",
      "Iteration 611, loss = 0.00721493\n",
      "Iteration 612, loss = 0.00692275\n",
      "Iteration 613, loss = 0.00690825\n",
      "Iteration 614, loss = 0.00689961\n",
      "Iteration 615, loss = 0.00699659\n",
      "Iteration 616, loss = 0.00698405\n",
      "Iteration 617, loss = 0.00700628\n",
      "Iteration 618, loss = 0.00683409\n",
      "Iteration 619, loss = 0.00682613\n",
      "Iteration 620, loss = 0.00702734\n",
      "Iteration 621, loss = 0.00682082\n",
      "Iteration 622, loss = 0.00721309\n",
      "Iteration 623, loss = 0.00689493\n",
      "Iteration 624, loss = 0.00674409\n",
      "Iteration 625, loss = 0.00680574\n",
      "Iteration 626, loss = 0.00678424\n",
      "Iteration 627, loss = 0.00675680\n",
      "Iteration 628, loss = 0.00672601\n",
      "Iteration 629, loss = 0.00674004\n",
      "Iteration 630, loss = 0.00670534\n",
      "Iteration 631, loss = 0.00671378\n",
      "Iteration 632, loss = 0.00671388\n",
      "Iteration 633, loss = 0.00664991\n",
      "Iteration 634, loss = 0.00665880\n",
      "Iteration 635, loss = 0.00668396\n",
      "Iteration 636, loss = 0.00660397\n",
      "Iteration 637, loss = 0.00680103\n",
      "Iteration 638, loss = 0.00675590\n",
      "Iteration 639, loss = 0.00657702\n",
      "Iteration 640, loss = 0.00657316\n",
      "Iteration 641, loss = 0.00659963\n",
      "Iteration 642, loss = 0.00654994\n",
      "Iteration 643, loss = 0.00653373\n",
      "Iteration 644, loss = 0.00655002\n",
      "Iteration 645, loss = 0.00652141\n",
      "Iteration 646, loss = 0.00653123\n",
      "Iteration 647, loss = 0.00660925\n",
      "Iteration 648, loss = 0.00648991\n",
      "Iteration 649, loss = 0.00660035\n",
      "Iteration 650, loss = 0.00669619\n",
      "Iteration 651, loss = 0.00651402\n",
      "Iteration 652, loss = 0.00687105\n",
      "Iteration 653, loss = 0.00653666\n",
      "Iteration 654, loss = 0.00656560\n",
      "Iteration 655, loss = 0.00641301\n",
      "Iteration 656, loss = 0.00647899\n",
      "Iteration 657, loss = 0.00650346\n",
      "Iteration 658, loss = 0.00645689\n",
      "Iteration 659, loss = 0.00638502\n",
      "Iteration 660, loss = 0.00637556\n",
      "Iteration 661, loss = 0.00639341\n",
      "Iteration 662, loss = 0.00636813\n",
      "Iteration 663, loss = 0.00634819\n",
      "Iteration 664, loss = 0.00636724\n",
      "Iteration 665, loss = 0.00644411\n",
      "Iteration 666, loss = 0.00634888\n",
      "Iteration 667, loss = 0.00633266\n",
      "Iteration 668, loss = 0.00630485\n",
      "Iteration 669, loss = 0.00629378\n",
      "Iteration 670, loss = 0.00630258\n",
      "Iteration 671, loss = 0.00632033\n",
      "Iteration 672, loss = 0.00633291\n",
      "Iteration 673, loss = 0.00633650\n",
      "Iteration 674, loss = 0.00626864\n",
      "Iteration 675, loss = 0.00631662\n",
      "Iteration 676, loss = 0.00630325\n",
      "Iteration 677, loss = 0.00626698\n",
      "Iteration 678, loss = 0.00623661\n",
      "Iteration 679, loss = 0.00629030\n",
      "Iteration 680, loss = 0.00625985\n",
      "Iteration 681, loss = 0.00632907\n",
      "Iteration 682, loss = 0.00627027\n",
      "Iteration 683, loss = 0.00632177\n",
      "Iteration 684, loss = 0.00628906\n",
      "Iteration 685, loss = 0.00619271\n",
      "Iteration 686, loss = 0.00618789\n",
      "Iteration 687, loss = 0.00618914\n",
      "Training loss did not improve more than tol=0.000100 for 100 consecutive epochs. Stopping.\n",
      "-> Validacion SKLearn MLP: 86.52%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# codigo del mlp de sklearn\n",
    "\n",
    "# valores que vamos tocando\n",
    "LAYERS=(62, 70)\n",
    "LAMBDA=0.001\n",
    "LR_INIT=0.5\n",
    "ITERATIONS=10000\n",
    "\n",
    "mlp_sklearn = MLPClassifier(\n",
    "        hidden_layer_sizes=LAYERS,\n",
    "        activation='logistic',     \n",
    "        solver='sgd',             \n",
    "        max_iter=ITERATIONS,\n",
    "        learning_rate=\"constant\",\n",
    "        learning_rate_init=LR_INIT,\n",
    "        alpha=LAMBDA,             \n",
    "        random_state=42,\n",
    "        n_iter_no_change=100,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "mlp_sklearn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_sklearn = mlp_sklearn.predict(X_test)\n",
    "\n",
    "acc_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "\n",
    "print(f\"-> Validacion SKLearn MLP: {acc_sklearn * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11841086",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "   | pros | cons | \n",
    "   |---|---|\n",
    "   | caja blanca | sensible a irrelevancias y ruido |\n",
    "   | entrenamiento rapido | ejecucion lenta |\n",
    "   | tolerancia a la forma de los datos | costoso en memoria |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6920e659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validacion KNN: 82.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# codigo del KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"-> Validacion KNN: {acc_knn * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39e3fc",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "\n",
    "   | pros | cons | \n",
    "   |---|---|\n",
    "   | caja blanca | sensible al ruido |\n",
    "   | entrenamiento rapido | simple |\n",
    "   | agradecido con los datos | tiende al overfitting si no hay limite de profunidad |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "594211dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validacion DT: 80.90%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# codigo del decision tree\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"-> Validacion DT: {acc_dt * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25777d0d",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "   | pros | cons | \n",
    "   |---|---|\n",
    "   | facil de calcular | caja gris (blanca por el dt, negra por la votacion) |\n",
    "   | valora la relevancia de los datos | sensible al ruido, tiende al overfitting |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d2d1fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validacion RF: 89.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# codigo del random forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"-> Validacion RF: {acc_rf * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2740c69",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac4716",
   "metadata": {},
   "source": [
    "Accuracy o Precisin (tasa de exactitud): \n",
    "$\\Large\\frac{TP+TN}{TP+N+FP+FN} = \\frac{V}{F}$\n",
    "\n",
    "Recall (ratio de positivos reales): $\\Large\\frac{TP}{TP+FN}$\n",
    "\n",
    "Precision (ratio de clasificaciones correctas) : $\\Large\\frac{TP}{TP+FP}$\n",
    "\n",
    "\n",
    "   |  Datos predichos | Positive Observed | Negative Observed |  Datos reales |\n",
    "   |---|---|---|---|\n",
    "   | Positive Predicted | TP | FP | Precision |\n",
    "   | Negative Predicted | FP | TN |   |\n",
    "   |  Datos predichos | Recall |  | |\n",
    "\n",
    "F1Score: $\\Large\\frac{Precision*Recall}{Precision+Recall}$\n",
    "\n",
    "Mide el equilibrio entre el Recall y el Precision entre 0 y 1, 1 seria un clasificador perfecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d575bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Accuracy/Precisin Custom MLP: 85.39%\n",
      "-> Recall Custom MLP: 85.39%\n",
      "-> Precision Custom MLP: 73.02%\n",
      "-> F1 Score Custom MLP: 71.88%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAGwCAYAAAAXAEo1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIuBJREFUeJzt3XtU1HXi//HXgNxEQFEhUfCel7yLGWlmN8vKpNqy1S111X6WlzxU7rpWaoWoldcWU3dTc3PT1bxsF8str6WZhnlDy7ygKYmrMQKJAp/vH67za0KLwRk+b+T5OIdzdj4zDK+V8tlnZmAclmVZAgDAYH52DwAA4LcQKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjFfJ7gFXoqioSMeOHVNYWJgcDofdcwAAHrIsS2fOnFFMTIz8/C5//lSuY3Xs2DHFxsbaPQMAcIWOHDmiOnXqXPb6ch2rsLAwSVLGptUKrxJq8xr4XNVouxegLOX+aPcClAFnTo7i4m92/X1+OeU6Vhcf+guvEqrwsCo2r4HPhf/6P8y4yvgV2L0AZei3nsrhBRYAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWJUT7035u56o18nt40/xPeyeBR/59rMtSu01SH9ukqAnIhpq+3sf2z0JZWDVjLl6ona8Fr/wmt1TjGN7rFJTU1W/fn0FBwerffv22rBhg92TjFXr2vqasGWl6+O5j96yexJ8JD8vT7VbNFWvV8baPQVl5ND23dr49jLVbtbY7ilGqmTnF1+0aJFGjBih1NRUderUSbNmzVL37t21Z88excXF2TnNSP7+/oqIqm73DJSBFnd0VYs7uto9A2XkbG6e5g59Xn0mjdaH0/9u9xwj2XpmNXnyZA0YMEADBw5Us2bNNHXqVMXGxmrmzJl2zjLWiUNH9efr79NznX+nvw19QVkZ39s9CYAXvPOXiWpxWyc169LR7inGsi1W586d07Zt29StWze34926ddPnn39+yc/Jz8+X0+l0+6go6rVprr6Tn9Owt6aoz4Q/yZl1Sq8+MFg5p7PtngbgCny54iMd2bVXiaOG2j3FaLbF6uTJkyosLFR0dLTb8ejoaGVmZl7yc1JSUhQREeH6iI2NLYupRmhxS4Ladb9FtZs2VLPOHTRk7iuSpM1LP7R5GYDSOvV9pv71wmvqP/0lBQQH2T3HaLY+ZyVJDofD7bJlWcWOXTRq1CglJSW5LjudzgoVrJ8LqhyimKYNdOLgEbunACiljJ17debkKaV0f9R1rKiwUPs3p2ndvMWacfBz+fn727jQHLbFqkaNGvL39y92FnXixIliZ1sXBQUFKSiI//qQpPP555S5/7AadWht9xQApdS0cwc998k7bscWJL2o6IZ11W1IX0L1M7bFKjAwUO3bt9fq1at1//33u46vXr1aPXv2tGuWsZYmv66Wt3VSZO1onTl5Wh++Pl9nc3J1w4N32z0NPnA2J1dZBw67Lv/38FEd2bFHodWqKjI2xsZl8KbgKqGq3bSR27HAysEKrVa12PGKztaHAZOSkvToo48qPj5eCQkJmj17tjIyMjR48GA7Zxnp9PETenP4GOWczlaVyKqq3/Y6jVw2W9XrXGP3NPhARtpOTbm3j+vykr8kS5Ju6P2A+s58xa5ZgG0clmVZdg5ITU3VpEmTdPz4cbVo0UJTpkxRly5dSvS5TqdTERER+nHn5woPq+LjpbBdNcJcoeSctnsByoDzTI6qNm2v7OxshYeHX/Z2tsfqShCrCoZYVSzEqkIoaaxs/3VLAAD8FmIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA41Wye4BXVKkmhYXZvQI+tuXadnZPQBnqeGCX3RNQBhx+ISW6HWdWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKAGA8YgUAMB6xAgAYr1JJbjR9+vQS3+Hw4cNLPQYAgEspUaymTJlSojtzOBzECgDgdSWK1cGDB329AwCAyyr1c1bnzp3Tvn37VFBQ4M09AAAU43Gs8vLyNGDAAFWuXFnXXXedMjIyJF14rmrChAleHwgAgMexGjVqlL7++mutXbtWwcHBruO33367Fi1a5NVxAABIJXzO6ueWL1+uRYsW6YYbbpDD4XAdb968ub777juvjgMAQCrFmVVWVpaioqKKHc/NzXWLFwAA3uJxrDp06KD333/fdflioObMmaOEhATvLQMA4H88fhgwJSVFd911l/bs2aOCggJNmzZNu3fv1qZNm7Ru3TpfbAQAVHAen1ndeOON+uyzz5SXl6eGDRvq448/VnR0tDZt2qT27dv7YiMAoILz+MxKklq2bKn58+d7ewsAAJdUqlgVFhZq2bJlSk9Pl8PhULNmzdSzZ09VqlSquwMA4Fd5XJddu3apZ8+eyszMVJMmTSRJ33zzjWrWrKmVK1eqZcuWXh8JAKjYPH7OauDAgbruuut09OhRffXVV/rqq6905MgRtWrVSo8//rgvNgIAKjiPz6y+/vprbd26VdWqVXMdq1atmpKTk9WhQwevjgMAQCrFmVWTJk30ww8/FDt+4sQJNWrUyCujAAD4uRLFyul0uj7Gjx+v4cOHa8mSJTp69KiOHj2qJUuWaMSIEZo4caKv9wIAKqASPQxYtWpVt1+lZFmWHn74Ydcxy7IkST169FBhYaEPZgIAKrISxWrNmjW+3gEAwGWVKFY333yzr3cAAHBZpf4p3ry8PGVkZOjcuXNux1u1anXFowAA+DmPY5WVlaX+/fvrww8/vOT1PGcFAPA2j1+6PmLECJ0+fVqbN29WSEiIVq1apfnz56tx48ZauXKlLzYCACo4j8+sPv30U61YsUIdOnSQn5+f6tatqzvuuEPh4eFKSUnRPffc44udAIAKzOMzq9zcXNc7BUdGRiorK0vShd/E/tVXX3l3HQAAKsWZVZMmTbRv3z7Vq1dPbdq00axZs1SvXj298cYbqlWrli82QtKqKbO1/b3Vyvz2gAJCgtWwQ1sljnla1zSub/c0XKGoPr0U3aeXgmrHSJLyvt2v72e8oex1GyVJ1e68XVG/f0ihLZorILKadt7zoPLS99k5GT6wdvZ8rZ46S9mZJxTT7Fo9NGmMGnfqaPcsY5TqOavjx49LksaMGaNVq1YpLi5O06dP1/jx4z26r/Xr16tHjx6KiYmRw+HQ8uXLPZ1TYXz7+Ze6eUBvjfz4HT219O8qLCzQjN8NUH5unt3TcIXOHc9UxqQp2pXYS7sSe8m5aYuunTVDIY0bSpL8Q0KUsy1NRyZNtXcofGbrkpX618hx6j5ymEZ//qEa3Xi9Xr//MZ068r3d04zh8ZlVnz59XP+7bdu2OnTokPbu3au4uDjVqFHDo/vKzc1V69at1b9/fz344IOeTqlQhv1rjtvlx2aM18gmnZTx9W41vpFfIFye/fjpOrfLR1+brug+vVSlbWv99O13Orn835KkwP+deeHq858Zc9Spby917vd7SdLDr4zVnk/Wad2cBbr/xT/bvM4MV/xuiZUrV1a7du1K9bndu3dX9+7dr3RChfST84wkqXK1CJuXwKv8/BR5953yCwlRzlfb7V6DMlBw7pwy0nbqzqefdDve7NYuOvDFVptWmadEsUpKSirxHU6ePLnUY35Lfn6+8vPzXZedTqfPvpbJLMvSkucnquEN7VW72bV2z4EXhDRprOuWvC2/oEAV5uXpmyee0k/7D9g9C2Ug57+nVFRYqPComm7Hw6NryPmfLJtWmadEsUpLSyvRnf38l936QkpKisaNG+fTr1EevDPyJX2/e5+eef9tu6fAS84eOKid9z6oSuHhirzrDjV8JVnpv+9HsCqQX/79aVmW5OO/U8uTcvWLbEeNGuV2lud0OhUbG2vjorK36E8va+eqNUp6b4Gq1b7G7jnwEut8gfIPH1G+pNyduxXa6jpF9/uDDj33ot3T4GNVqkfKz99f2T+ccDt+5sR/FR7l2esArmYevxrQTkFBQQoPD3f7qCgsy9I7I19S2nurNWL5XNWoW8fuSfAlh0N+gYF2r0AZqBQYqLi2LZX+6Qa34+lrNqhBx3ibVpnnil9ggbLxzrMv6sul72vwP15XUJVQZf9w4bHskPAwBYYE27wOV6LOM08pe90G5R/LlH+VUFW/t7vCO3bQ3v6DJUn+EeEKiqmlgOgLP4wf3ODCz9adzzqp8yf/a9tueM/twwZp7sARqtu2lRp0bK8Nb76t00e+V5eBf7B7mjFsjVVOTo7279/vunzw4EFt375dkZGRiouLs3GZedbPfUeSNOW+vm7HH5sxXgm977djErwkoEZ1NXwtRQE1a6rwzBnl7ftGe/sPlnPjJklStdtvUcNXkl23bzzjVUnS0Wmp+n5aqi2b4V3xv7tPOadO6/0J0+TMPKGY5k009N35qh7HIygXOayLb/Nrg7Vr1+qWW24pdrxv376aN2/eb36+0+lURESEfjyYrvDwMB8shEm2NL/B7gkoQx0P7LJ7AsqA0+lURK04ZWdn/+pTO7aeWXXt2lU2thIAUE6U6gUWCxYsUKdOnRQTE6PDhw9LkqZOnaoVK1Z4dRwAAFIpYjVz5kwlJSXp7rvv1o8//uh6s8WqVatq6tSp3t4HAIDnsZoxY4bmzJmj0aNHy9/f33U8Pj5eO3fu9Oo4AACkUsTq4MGDatu2bbHjQUFBys3N9cooAAB+zuNY1a9fX9u3by92/MMPP1Tz5s29sQkAADcevxrw2Wef1ZAhQ3T27FlZlqUtW7bon//8p1JSUvS3v/3NFxsBABWcx7Hq37+/CgoKNHLkSOXl5al3796qXbu2pk2bpkceecQXGwEAFVypfs5q0KBBGjRokE6ePKmioiJFRUV5excAAC5X9EPBnr4zMAAApeFxrOrXr/+r71t14ADvvwMA8C6PYzVixAi3y+fPn1daWppWrVqlZ5991lu7AABw8ThWTz311CWP//Wvf9XWrVuveBAAAL/ktTdf7N69u5YuXeqtuwMAwMVrsVqyZIkiIyO9dXcAALh4/DBg27Zt3V5gYVmWMjMzlZWVpdRU3ggOAOB9HscqMTHR7bKfn59q1qyprl27qmnTpt7aBQCAi0exKigoUL169XTnnXfqmmuu8dUmAADcePScVaVKlfTEE08oPz/fV3sAACjG4xdYdOzYUWlpab7YAgDAJXn8nNWTTz6pp59+WkePHlX79u0VGhrqdn2rVq28Ng4AAMmDWP3xj3/U1KlT1atXL0nS8OHDXdc5HA5ZliWHw+F6m3sAALylxLGaP3++JkyYoIMHD/pyDwAAxZQ4VpZlSZLq1q3rszEAAFyKRy+w+LXftg4AgK949AKLa6+99jeDderUqSsaBADAL3kUq3HjxikiIsJXWwAAuCSPYvXII4/wFvYAgDJX4ueseL4KAGCXEsfq4qsBAQAoayV+GLCoqMiXOwAAuCyvvfkiAAC+QqwAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGK+S3QO8Ij9POkt3r3bXf/OV3RNQhgaH1rF7AsrAOVkluh1/wwMAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWJVTq2bM1RO147X4hdfsngIf+PazLUrtNUh/bpKgJyIaavt7H9s9CT5w5zND9EbuUT00aazrWJv7umvYin/o1cM79EbuUdVp1dy+gQYhVuXQoe27tfHtZardrLHdU+Aj+Xl5qt2iqXq9MtbuKfCRuu1a66b+fXR05x6340GhlfXdpq1a9kKKTcvMZGusUlJS1KFDB4WFhSkqKkqJiYnat2+fnZOMdzY3T3OHPq8+k0arctUwu+fAR1rc0VU9n39abe+70+4p8IGg0Mr645sz9I+hI5V3Otvtui/+uVQfTJiqvWs22LTOTLbGat26dRoyZIg2b96s1atXq6CgQN26dVNubq6ds4z2zl8mqsVtndSsS0e7pwAopUemJGvXR59o75qNdk8pNyrZ+cVXrVrldnnu3LmKiorStm3b1KVLl2K3z8/PV35+vuuy0+n0+UaTfLniIx3ZtVd/fv8tu6cAKKX4392nuDYtlXLTPXZPKVeMes4qO/vC6XBkZOQlr09JSVFERITrIzY2tizn2erU95n61wuvqf/0lxQQHGT3HAClUK12LT38yji9OWCYCn72H974bbaeWf2cZVlKSkpS586d1aJFi0veZtSoUUpKSnJddjqdFSZYGTv36szJU0rp/qjrWFFhofZvTtO6eYs14+Dn8vP3t3EhgN8S17aVwqNq6i8bP3Qd869USY06d1TX/9dPQ6s1kFVUZONCcxkTq6FDh2rHjh3auPHyj+EGBQUpKKhinlU07dxBz33yjtuxBUkvKrphXXUb0pdQAeXA3rUb9WKH29yOPfbGa8r85jt9PDmVUP0KI2I1bNgwrVy5UuvXr1edOnXsnmOk4Cqhqt20kduxwMrBCq1WtdhxlH9nc3KVdeCw6/J/Dx/VkR17FFqtqiJjY2xchiuRn5OrY3vcX/F8Lvcn5Z467Tpe+X/f46q1rpEkRTduKEly/pAl5w9ZZTvYILbGyrIsDRs2TMuWLdPatWtVv359O+cAxshI26kp9/ZxXV7yl2RJ0g29H1Dfma/YNQtloPU9d6jvrCmuy4PemilJei95st4bP9muWbZzWJZl2fXFn3zySS1cuFArVqxQkyZNXMcjIiIUEhLym5/vdDoVERGhH/duU3hYFV9OhQmqVLN7AcrQExEN7J6AMnBOluYqV9nZ2QoPD7/s7Wx9NeDMmTOVnZ2trl27qlatWq6PRYsW2TkLAGAY2x8GBADgtxj1c1YAAFwKsQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA4xErAIDxiBUAwHjECgBgPGIFADAesQIAGI9YAQCMR6wAAMYjVgAA41Wye8CVsCxLkuTMybF5CcpEUbn+xxUeOifL7gkoAxe/zxf/Pr+ccv1v/5kzZyRJcfE327wEAHAlzpw5o4iIiMte77B+K2cGKyoq0rFjxxQWFiaHw2H3nDLjdDoVGxurI0eOKDw83O458CG+1xVHRf1eW5alM2fOKCYmRn5+l39mqlyfWfn5+alOnTp2z7BNeHh4hfqHuiLje11xVMTv9a+dUV3ECywAAMYjVgAA4xGrcigoKEhjxoxRUFCQ3VPgY3yvKw6+17+uXL/AAgBQMXBmBQAwHrECABiPWAEAjEesAADGI1blTGpqqurXr6/g4GC1b99eGzZssHsSfGD9+vXq0aOHYmJi5HA4tHz5crsnwUdSUlLUoUMHhYWFKSoqSomJidq3b5/ds4xDrMqRRYsWacSIERo9erTS0tJ00003qXv37srIyLB7GrwsNzdXrVu31uuvv273FPjYunXrNGTIEG3evFmrV69WQUGBunXrptzcXLunGYWXrpcjHTt2VLt27TRz5kzXsWbNmikxMVEpKSk2LoMvORwOLVu2TImJiXZPQRnIyspSVFSU1q1bpy5dutg9xxicWZUT586d07Zt29StWze34926ddPnn39u0yoA3padnS1JioyMtHmJWYhVOXHy5EkVFhYqOjra7Xh0dLQyMzNtWgXAmyzLUlJSkjp37qwWLVrYPcco5fq3rldEv3wrFMuyKtTbowBXs6FDh2rHjh3auHGj3VOMQ6zKiRo1asjf37/YWdSJEyeKnW0BKH+GDRumlStXav369RX6rY8uh4cBy4nAwEC1b99eq1evdju+evVq3XjjjTatAnClLMvS0KFD9e677+rTTz9V/fr17Z5kJM6sypGkpCQ9+uijio+PV0JCgmbPnq2MjAwNHjzY7mnwspycHO3fv991+eDBg9q+fbsiIyMVFxdn4zJ425AhQ7Rw4UKtWLFCYWFhrkdPIiIiFBISYvM6c/DS9XImNTVVkyZN0vHjx9WiRQtNmTKFl7dehdauXatbbrml2PG+fftq3rx5ZT8IPnO555znzp2rfv36le0YgxErAIDxeM4KAGA8YgUAMB6xAgAYj1gBAIxHrAAAxiNWAADjESsAgPGIFQDAeMQKuEJjx45VmzZtXJf79etnyxslHjp0SA6HQ9u3b7/sberVq6epU6eW+D7nzZunqlWrXvE2h8Oh5cuXX/H9oOIiVrgq9evXTw6HQw6HQwEBAWrQoIGeeeaZMnmr8GnTppX4VyKVJDAA+EW2uIrdddddmjt3rs6fP68NGzZo4MCBys3N1cyZM4vd9vz58woICPDK142IiPDK/QD4/zizwlUrKChI11xzjWJjY9W7d2/16dPH9VDUxYfu3nzzTTVo0EBBQUGyLEvZ2dl6/PHHFRUVpfDwcN166636+uuv3e53woQJio6OVlhYmAYMGKCzZ8+6Xf/LhwGLioo0ceJENWrUSEFBQYqLi1NycrIkud4Oom3btnI4HOratavr8+bOnatmzZopODhYTZs2VWpqqtvX2bJli9q2bavg4GDFx8crLS3N4z+jyZMnq2XLlgoNDVVsbKyefPJJ5eTkFLvd8uXLde211yo4OFh33HGHjhw54nb9v//9b7Vv317BwcFq0KCBxo0bp4KCAo/3AJdDrFBhhISE6Pz5867L+/fv1+LFi7V06VLXw3D33HOPMjMz9cEHH2jbtm1q166dbrvtNp06dUqStHjxYo0ZM0bJycnaunWratWqVSwivzRq1ChNnDhRzz//vPbs2aOFCxe63jBzy5YtkqT//Oc/On78uN59911J0pw5czR69GglJycrPT1d48eP1/PPP6/58+dLknJzc3XvvfeqSZMm2rZtm8aOHatnnnnG4z8TPz8/TZ8+Xbt27dL8+fP16aefauTIkW63ycvLU3JysubPn6/PPvtMTqdTjzzyiOv6jz76SH/4wx80fPhw7dmzR7NmzdK8efNcQQa8wgKuQn379rV69uzpuvzFF19Y1atXtx5++GHLsixrzJgxVkBAgHXixAnXbT755BMrPDzcOnv2rNt9NWzY0Jo1a5ZlWZaVkJBgDR482O36jh07Wq1bt77k13Y6nVZQUJA1Z86cS+48ePCgJclKS0tzOx4bG2stXLjQ7dhLL71kJSQkWJZlWbNmzbIiIyOt3Nxc1/UzZ8685H39XN26da0pU6Zc9vrFixdb1atXd12eO3euJcnavHmz61h6erolyfriiy8sy7Ksm266yRo/frzb/SxYsMCqVauW67Ika9myZZf9usBv4TkrXLXee+89ValSRQUFBTp//rx69uypGTNmuK6vW7euatas6bq8bds25eTkqHr16m7389NPP+m7776TJKWnpxd7s8uEhAStWbPmkhvS09OVn5+v2267rcS7s7KydOTIEQ0YMECDBg1yHS8oKHA9H5aenq7WrVurcuXKbjs8tWbNGo0fP1579uyR0+lUQUGBzp49q9zcXIWGhkqSKlWqpPj4eNfnNG3aVFWrVlV6erquv/56bdu2TV9++aXbmVRhYaHOnj2rvLw8t41AaRErXLVuueUWzZw5UwEBAYqJiSn2AoqLfxlfVFRUpFq1amnt2rXF7qu0L98uzTu9FhUVSbrwUGDHjh3drvP395d04a3Qr9Thw4d19913a/DgwXrppZcUGRmpjRs3asCAAW4Pl0qXfoPAi8eKioo0btw4PfDAA8VuExwcfMU7AYlY4SoWGhqqRo0alfj27dq1U2ZmpipVqqR69epd8jbNmjXT5s2b9dhjj7mObd68+bL32bhxY4WEhOiTTz7RwIEDi10fGBgo6cKZyEXR0dGqXbu2Dhw4oD59+lzyfps3b64FCxbop59+cgXx13ZcytatW1VQUKDXXntNfn4Xnr5evHhxsdsVFBRo69atuv766yVJ+/bt048//qimTZtKuvDntm/fPo/+rAFPESvgf26//XYlJCQoMTFREydOVJMmTXTs2DF98MEHSkxMVHx8vJ566in17dtX8fHx6ty5s95++23t3r1bDRo0uOR9BgcH609/+pNGjhypwMBAderUSVlZWdq9e7cGDBigqKgohYSEaNWqVapTp46Cg4MVERGhsWPHavjw4QoPD1f37t2Vn5+vrVu36vTp00pKSlLv3r01evRoDRgwQM8995wOHTqkV1991aP/vw0bNlRBQYFmzJihHj166LPPPtMbb7xR7HYBAQEaNmyYpk+froCAAA0dOlQ33HCDK14vvPCC7r33XsXGxuqhhx6Sn5+fduzYoZ07d+rll1/2/BsBXIrdT5oBvvDLF1j80pgxY9xeFHGR0+m0hg0bZsXExFgBAQFWbGys1adPHysjI8N1m+TkZKtGjRpWlSpVrL59+1ojR4687AssLMuyCgsLrZdfftmqW7euFRAQYMXFxbm9IGHOnDlWbGys5efnZ918882u42+//bbVpk0bKzAw0KpWrZrVpUsX691333Vdv2nTJqt169ZWYGCg1aZNG2vp0qUev8Bi8uTJVq1atayQkBDrzjvvtN566y1LknX69GnLsi68wCIiIsJaunSp1aBBAyswMNC69dZbrUOHDrnd76pVq6wbb7zRCgkJscLDw63rr7/emj17tut68QILXCGHZXnhwW8AAHyIn7MCABiPWAEAjEesAADGI1YAAOMRKwCA8YgVAMB4xAoAYDxiBQAwHrECABiPWAEAjEesAADG+z9THMeYpAfCCgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Matriz de confusion (con una)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_sklearn, cmap=\"Reds\", colorbar=False)\n",
    "\n",
    "# ACCURACY\n",
    "acc_custom = accuracy_score(y_test, y_pred)\n",
    "print(f\"-> Accuracy/Precisin Custom MLP: {acc_custom * 100:.2f}%\")\n",
    "\n",
    "# RECALL\n",
    "recall_custom = recall_score(y_test, y_pred, average='micro')\n",
    "print(f\"-> Recall Custom MLP: {recall_custom * 100:.2f}%\")\n",
    "\n",
    "# PRECISION\n",
    "prec_custom = precision_score(y_test, y_pred, average='macro')\n",
    "print(f\"-> Precision Custom MLP: {prec_custom * 100:.2f}%\")\n",
    "\n",
    "# F1 Score\n",
    "f1_custom = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"-> F1 Score Custom MLP: {f1_custom * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c1a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SKLearn\\nAcc: 80.90%')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Matriz de confusion (con varias)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_sklearn, ax=axes[0], cmap=\"Reds\", colorbar=False)\n",
    "axes[0].set_title(f\"MLP\\nAcc: {acc_custom * 100:.2f}%\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_dt, ax=axes[1], cmap=\"Reds\", colorbar=False)\n",
    "axes[1].set_title(f\"SKLearn\\nAcc: {acc_dt * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de02b1",
   "metadata": {},
   "source": [
    "### DIAGNOSTICO\n",
    "\n",
    "   | (coste) | validacion baja | validacion alta | \n",
    "   |---|---|---|\n",
    "   | entrenamiento bajo | precision alta (lo que queremos) | overfitting (overfitting, tmb se puede ir subiendo lambda con cuidado) |\n",
    "   | entrenamiento alto | datos de validacion sesgados (modelo mal) | modelo mal |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
