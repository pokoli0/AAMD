{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "060c0eca",
   "metadata": {},
   "source": [
    "# Guia para hacer un modelo de ia del examen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799919a5",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Limpiar los datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b4536",
   "metadata": {},
   "source": [
    "QUITANDO FILAS Y COLUMNAS Y NORMALIZANDO DATOS\n",
    "\n",
    "Para normalizar los datos hay que tener en cuenta que:\n",
    "    \n",
    "* Discretos/Enumerados/Cualitativos -> OneHotEncoding o Labled Encoder\n",
    "        OneHotEncoding -> por defecto, si dudas usa este\n",
    "        LabledEncoder -> si los valores tienen un orden\n",
    "\n",
    "* Continuos -> StandardScaling, para normalizarlos y llevarlos a una escala comun\n",
    "\n",
    "\n",
    "\n",
    "        solo deberia hacer falta copiar este codigo y cambiar las columnas en ATRIBUTOS, en final_data salen todos los datos sin el atributo solucion y en labeled_data el solucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3a95d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import glob as glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar el dataset\n",
    "data = pd.read_csv('dementia_dataset.csv')\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / GESTI√ìN DE NULOS / ------------------- \n",
    "# ----- DIAGNOSTICO\n",
    "# print(\"--- INFO ---\")\n",
    "# print(data.info())\n",
    "# print(\"\\n--- NULOS POR COLUMNA ---\")\n",
    "# print(data.isnull().sum()) # ¬°ESTO ES CRUCIAL!\n",
    "# Si ves una columna con 50% de nulos -> A la lista 'unnecessary_columns'\n",
    "# Si ves una columna con 5% de nulos -> Imputar (media) o Borrar filas\n",
    "\n",
    "# Cuantos datos perderiamos: \n",
    "    # Si se pierden 10-15 filas OPCION A\n",
    "    # si se pierden 50-100 filas OPCION B\n",
    "\n",
    "# ----- QUITAR / MODIFICAR NULOS\n",
    "# OPCI√ìN A : Borrar filas con huecos.\n",
    "# √ösalo si tienes muchos datos (>1000) y pocos huecos.\n",
    "# data = data.dropna(how=\"any\")\n",
    "\n",
    "# OPCI√ìN B (Alternativa si tienes pocos datos): IMPUTAR\n",
    "# Si ves que al hacer dropna te quedas con muy pocas filas, usa esto antes de escalar:\n",
    "# data['SES'] = data['SES'].fillna(data['SES'].mean()) # Imputa la media en los huecos de SES (ejemplo num√©rico)\n",
    "# SES: Es un valor socioecon√≥mico (float). Usamos la mediana porque es m√°s robusta.\n",
    "#data['SES'] = data['SES'].fillna(data['SES'].median())\n",
    "# MMSE: Es un test mental. Usamos la media (o mediana, ambas valen).\n",
    "#data['MMSE'] = data['MMSE'].fillna(data['MMSE'].mean())\n",
    "# Verificamos que ya no quedan nulos\n",
    "#print(\"Nulos restantes:\", data.isnull().sum().sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------- / ATRIBUTOS / ---------------------\n",
    "unnecessary_columns = []\n",
    "oneHot_columns = [\"Sex\", \"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\", \"FastingBS\"] # VALORES CATEG√ìRICOS A OHE, o 0/1\n",
    "standardScaling_columns = [\"Age\", \"RestingBP\",\"Cholesterol\", \"MaxHR\", \"Oldpeak\"] # VALORES NUMERICOS A ESCALAR, menos los que sean 0 y 1\n",
    "labeled_columns = [\"HeartDisease\"] # SOLUCION\n",
    "\n",
    "solucion = \"HeartDisease\" # Nombre de la columna soluci√≥n\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / DROP /  -------------------\n",
    "# Borramos lo que no sirve para limpiar el ruido del dataset.\n",
    "final_data = data.drop(columns=unnecessary_columns) \n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / OHE /  -------------------\n",
    "encoder = OneHotEncoder(sparse_output=False) \n",
    "encoder_final = encoder.fit_transform(data[oneHot_columns])  \n",
    "# Creamos un DF temporal con nombres bonitos (ej: \"M/F_M\", \"M/F_F\")\n",
    "oneHot_df = pd.DataFrame(\n",
    "    encoder_final, \n",
    "    columns=encoder.get_feature_names_out(oneHot_columns), \n",
    "    index=data.index  # <--- ¬°ESTO ES LO QUE FALTABA!\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------- / SCALER /  -------------------\n",
    "# Transforma los datos para que tengan media 0 y desviaci√≥n t√≠pica 1 (Curva de Gauss).\n",
    "scaler = StandardScaler()\n",
    "scaler_final = scaler.fit_transform(data[standardScaling_columns])\n",
    "df_sc = pd.DataFrame(scaler_final, columns=standardScaling_columns, index=data.index)\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- / LABELED ENCODER / -------------------------   \n",
    "# Convierte \"Demented\" -> 0, \"Nondemented\" -> 1, etc.\n",
    "labler = LabelEncoder()\n",
    "labeled_final = labler.fit_transform(data[labeled_columns].values.ravel()) # o labeled_final = labler.fit_transform(data[labeled_columns])\n",
    "df_lbl = pd.DataFrame(labeled_final, columns=labeled_columns, index=data.index)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# ---------------- / CONCATENAR (SOLUCION AL FINAL) / -------------------\n",
    "# ---- 1. Juntamos las 3 partes: Num√©ricos Escalados + Categ√≥ricos OHE + Soluci√≥n Codificada\n",
    "final_data = pd.concat([df_sc, oneHot_df, df_lbl], axis=1) #axis=1 significa \"pegar columnas a la derecha\"\n",
    "\n",
    "\n",
    "# print(\"\\nColumnas finales:\")\n",
    "# print(final_data.columns.tolist()) # Verifica que NO hay \"algo_nan\", si lo hay es que no se han gestionado bien los nulos.\n",
    "\n",
    "# final_data.head()\n",
    "\n",
    "# ---------------- / OPCIONAL / -------------------\n",
    "# # Opcional: prints para verificar\n",
    "# print(\"Tama√±o final del dataset:\", final_data.shape)\n",
    "# # para guardarlas en un archivo (opcional)\n",
    "# final_data.to_csv(\"./examen_limpio.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5dcc29",
   "metadata": {},
   "source": [
    "### Slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840621b",
   "metadata": {},
   "source": [
    "La sintaxis de slicing ([:]) es la herramienta n√∫mero 1 para trocear tus datos. Casi siempre tendr√°s un CSV donde la √∫ltima columna es la soluci√≥n (ej: HeartDisease o Group). Usando pandas: \n",
    "* dataset.iloc[:, :-1] $\\to$ Coge TODAS las filas (:) y TODAS las columnas MENOS la √∫ltima (:-1). $\\to$ Esto es tu X.dataset.\n",
    "* iloc[:, -1] $\\to$ Coge TODAS las filas (:) y SOLO la √∫ltima columna (-1). $\\to$ Esto es tu y.\n",
    "\n",
    "#### Ejemplo pr√°ctico de examen\n",
    "1. Separar features y target\n",
    "* X = final_data.iloc[:, :-1]  # Todo menos la soluci√≥n\n",
    "* y = final_data.iloc[:, -1]   # Solo la soluci√≥n\n",
    "\n",
    "2. Dividir datos manualmente (Train / Test)\n",
    "Si no te dejan usar train_test_split de sklearn (raro, pero posible) o si son series temporales (donde no puedes mezclar aleatoriamente):\n",
    "* datos[:800] $\\to$ Coge desde el principio hasta la fila 800 (Entrenamiento).\n",
    "* datos[800:] $\\to$ Coge desde la fila 800 hasta el final (Test).\n",
    "\n",
    "3. Im√°genes (CNNs)\n",
    "Si te cae algo de im√°genes (matrices 3D: Alto, Ancho, Canales):\n",
    "* imagen[:, ::-1] $\\to$ Invierte la imagen horizontalmente (Efecto espejo para Data Augmentation).\n",
    "* imagen[10:100, 10:100] $\\to$ Recorta la imagen (Crop) para quitar bordes in√∫tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d9b079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "start = 0\n",
    "stop = 2\n",
    "step = 1\n",
    "\n",
    "a[start:stop]  # items start through stop-1\n",
    "a[start:]      # items start through the rest of the array\n",
    "a[:stop]       # items from the beginning through stop-1\n",
    "a[:]           # a copy of the whole array\n",
    "\n",
    "# ---------------------------------------------\n",
    "\n",
    "a[start:stop:step] # start through not past stop, by step\n",
    "\n",
    "# ---------------------------------------------\n",
    "\n",
    "a[-1]    # last item in the array\n",
    "a[-2:]   # last two items in the array\n",
    "a[:-2]   # everything except the last two items\n",
    "\n",
    "# ---------------------------------------------\n",
    "\n",
    "a[::-1]    # all items in the array, reversed\n",
    "a[1::-1]   # the first two items, reversed\n",
    "a[:-3:-1]  # the last two items, reversed\n",
    "a[-3::-1]  # everything except the last two items, reversed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a2ba7",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Representar los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e059d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# -------------------- / PREPARACI√ìN / -------------------\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m x \u001b[38;5;241m=\u001b[39m final_data                          \u001b[38;5;66;03m# x: Son tus datos limpios (sin la soluci√≥n). Ya lo tienes del Ejercicio 1.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m=\u001b[39m labeled_data\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel()     \u001b[38;5;66;03m# y: Es la columna de soluci√≥n. √ösala directa de 'labeled_data' (Ejercicio 1).\u001b[39;00m\n\u001b[0;32m      9\u001b[0m                                         \u001b[38;5;66;03m# .values.ravel() asegura que sea un array plano y no de problemas.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# clase: TIENE QUE SER UN STRING, NO UNA LISTA\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_data' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# -------------------- / PREPARACI√ìN / -------------------\n",
    "# Usamos nombres distintos (_vis) para no machacar las variables del modelo (X, y)\n",
    "X_vis = final_data.drop(columns=[solucion])      # Datos para el PCA\n",
    "y_vis = df_lbl.values.ravel() # Etiquetas para colorear (flattened)\n",
    "\n",
    "# puede que antes de PCA sea necesario usar los datos listos para el MODELO (SIGUIENTE CELDA):\n",
    "# X_vis = final_data.drop(columns=[solucion]) # Datos sin la columna soluci√≥n\n",
    "# y_vis = y\n",
    "\n",
    "\n",
    "# clase: TIENE QUE SER UN STRING, NO UNA LISTA\n",
    "clase = \"Group\"        # variable solucion\n",
    "\n",
    "\n",
    "# ---------------- / DISTRIBUCI√ìN DE CLASES / -------------------\n",
    "# √ösalo si piden \"Ver distribuci√≥n de clases\" o \"Balanceo del dataset\"\n",
    "print(f\"--- Distribuci√≥n de {clase} ---\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# TRUCO PRO: Usamos 'data' (el original) en vez de 'labeled_data' para que\n",
    "# en el gr√°fico salgan los nombres (\"Demented\") en vez de n√∫meros (0, 1).\n",
    "# Si usas 'labeled_data' saldr√°n 0, 1, 2.\n",
    "                                      \n",
    "data[clase].value_counts().plot(kind='bar', color=['skyblue', 'orange']) # pon mas colores si hace falta\n",
    "plt.title(f\"Distribuci√≥n de la variable objetivo: {clase}\")\n",
    "plt.xlabel(\"Clases\")\n",
    "plt.ylabel(\"Cantidad de pacientes\")\n",
    "plt.xticks(rotation=0) # Para que las letras se lean rectas\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------- / PCA (Reducci√≥n) / ------------------------ \n",
    "pca_comp = PCA(n_components=2)\n",
    "# ¬°OJO! X_vis tiene que ser SOLO N√öMEROS.\n",
    "x_pca = pca_comp.fit_transform(X_vis)\n",
    "\n",
    "# Cuanta info mantenemos:\n",
    "print(f\"Varianza explicada: {pca_comp.explained_variance_ratio_.sum():.2f}\") \n",
    "\n",
    "df_pca = pd.DataFrame({\n",
    "    \"c1\": x_pca[:, 0],    # Componente Principal 1\n",
    "    \"c2\": x_pca[:, 1],    # Componente Principal 2\n",
    "    clase: y_vis             # el color (0,1,2...)\n",
    "})\n",
    "\n",
    "grupos = sorted(df_pca[clase].unique()) # [0, 1, 2]\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------- / PINTADO / ------------------------ \n",
    "# Colores: Usamos un mapa de colores autom√°tico\n",
    "colormap = plt.get_cmap(\"viridis\")\n",
    "colors = colormap(np.linspace(0, 1, len(grupos)))\n",
    "\n",
    "for i, g in enumerate(grupos):\n",
    "    # Filtramos los puntos de ese grupo\n",
    "    subset = df_pca[df_pca[clase] == g]\n",
    "    \n",
    "    # --- ETIQUETAS REALES (Demented vs 0) ---\n",
    "    # Intentamos recuperar el nombre real usando el 'labler' del Ejercicio 1.\n",
    "    try:\n",
    "        nombre_real = labler.inverse_transform([g])[0]\n",
    "    except:\n",
    "        nombre_real = f\"Clase {g}\" # Si falla, ponemos Clase 0, Clase 1...\n",
    "    \n",
    "    plt.scatter(\n",
    "        subset[\"c1\"], \n",
    "        subset[\"c2\"],\n",
    "        color=colors[i],\n",
    "        alpha=0.7,\n",
    "        s=80,             # Tama√±o del punto\n",
    "        label=nombre_real # ¬°Importante para la leyenda!\n",
    "    )\n",
    "\n",
    "plt.legend(title=\"Estado del Paciente\")\n",
    "plt.title(\"PCA: Visualizaci√≥n de datos tras limpieza\")\n",
    "plt.xlabel(f\"Componente 1 ({pca_comp.explained_variance_ratio_[0]*100:.1f}% var)\")\n",
    "plt.ylabel(f\"Componente 2 ({pca_comp.explained_variance_ratio_[1]*100:.1f}% var)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12cc7f",
   "metadata": {},
   "source": [
    "## PREPARACION EJERCICIOS 3 en adelante\n",
    "HAY QUE SEPARAR la columna solucion de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae303c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- / SEPARAR X (DATOS) e Y (SOLUCI√ìN) / -------------------\n",
    "# PASO A: Sacamos la Y (Solo la columna soluci√≥n)\n",
    "# .values.ravel() convierte la columna en un array plano [0, 1, 2, ...]\n",
    "y = final_data[solucion].values.ravel() \n",
    "\n",
    "# PASO B: Sacamos la X (Datos MENOS la soluci√≥n)\n",
    "X = final_data.drop(columns=[solucion])     # Pandas DataFrame (para ver nombres columnas si quieres)\n",
    "X_numpy = X.values                          # Numpy Array (para los modelos)\n",
    "\n",
    "# VERIFICACI√ìN (M√≠ralo en el examen)\n",
    "# VERIFICACI√ìN (M√≠ralo en el examen)\n",
    "print(f\"Shape de X (Datos): {X_numpy.shape}\") # Ejemplo: (373, 12)\n",
    "print(f\"Shape de y (Target): {y.shape}\")       # Ejemplo: (373,)\n",
    "X.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79fde29",
   "metadata": {},
   "source": [
    "## Ejercicio 3: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# EJERCICIO 3: ENTRENAMIENTO Y EVALUACI√ìN DEL MLP\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. COPIA AQU√ç TU CLASE 'MultilayerPerceptron' ENTERA\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "class MultilayerPerceptron:\n",
    "    def __init__(self, layers, learning_rate=0.1, epochs=5000):\n",
    "        self.layers = layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.loss_history = []\n",
    "        \n",
    "        np.random.seed(42) \n",
    "        for i in range(len(layers) - 1):\n",
    "            limit = np.sqrt(6 / (layers[i] + layers[i+1]))\n",
    "            w = np.random.uniform(-limit, limit, (layers[i], layers[i+1]))\n",
    "            b = np.zeros((1, layers[i+1]))\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, a):\n",
    "        return a * (1 - a)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True)) \n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        activations = [X]\n",
    "        input_data = X\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = np.dot(input_data, self.weights[i]) + self.biases[i]\n",
    "            a = self.sigmoid(z) \n",
    "            activations.append(a)\n",
    "            input_data = a\n",
    "        z_last = np.dot(input_data, self.weights[-1]) + self.biases[-1]\n",
    "        activations.append(self.softmax(z_last))\n",
    "        return activations\n",
    "\n",
    "    def backpropagation(self, X, y_onehot, activations):\n",
    "        m = X.shape[0]\n",
    "        deltas = [activations[-1] - y_onehot]\n",
    "        for i in range(len(self.weights) - 2, -1, -1):\n",
    "            delta_prev = np.dot(deltas[-1], self.weights[i+1].T) * self.sigmoid_derivative(activations[i+1])\n",
    "            deltas.append(delta_prev)\n",
    "        deltas.reverse()\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * (np.dot(activations[i].T, deltas[i]) / m)\n",
    "            self.biases[i] -= self.learning_rate * (np.sum(deltas[i], axis=0, keepdims=True) / m)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = y.astype(int) \n",
    "        y_onehot = np.eye(len(np.unique(y)))[y]\n",
    "        print(f\"Entrenando MLP Propio: {self.layers}\")\n",
    "        for epoch in range(self.epochs):\n",
    "            activations = self.forward(X)\n",
    "            self.backpropagation(X, y_onehot, activations)\n",
    "            if epoch % (self.epochs // 10) == 0:\n",
    "                loss = -np.mean(np.sum(y_onehot * np.log(activations[-1] + 1e-8), axis=1))\n",
    "                self.loss_history.append(loss)\n",
    "                print(f\"   Epoch {epoch}: Loss {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.forward(X)[-1], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Divisi√≥n Train / Test (80% - 20%)\n",
    "# stratify=y_numpy es OBLIGATORIO en ex√°menes para que las clases est√©n balanceadas en el test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_numpy, y_numpy, test_size=0.2, random_state=42, stratify=y_numpy\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFIGURACI√ìN DE LA RED\n",
    "# ---------------------------------------------------------\n",
    "input_dim = X_train.shape[1]         # N√∫mero de neuronas de entrada (autom√°tico)\n",
    "output_dim = len(np.unique(y_numpy)) # N√∫mero de clases/salidas (autom√°tico)\n",
    "\n",
    "# EL ENUNCIADO PIDE: \"Prueba con m√°s de una capa oculta\".\n",
    "# Estructura: [Entrada, Oculta1, Oculta2, ..., Salida]\n",
    "# Recomendaci√≥n examen: Empieza con algo potente como [input, 64, 32, output]\n",
    "layer_structure = [input_dim, 64, 32, output_dim] \n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# INSTANCIAR Y ENTRENAR\n",
    "# ---------------------------------------------------------\n",
    "print(f\"--- Entrenando Modelo con estructura: {layer_structure} ---\")\n",
    "\n",
    "# CONSEJOS HIPERPAR√ÅMETROS SI EL ACCURACY ES BAJO:\n",
    "# 1. learning_rate: Prueba 0.1, 0.01, 0.001. Si es muy alto oscila, si es muy bajo no aprende.\n",
    "# 2. epochs: Sube a 10000 o 20000 si la curva de loss sigue bajando.\n",
    "mi_mlp = MultilayerPerceptron(layers=layer_structure, learning_rate=0.1, epochs=10000)\n",
    "\n",
    "mi_mlp.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EVALUACI√ìN Y RESULTADOS\n",
    "# ---------------------------------------------------------\n",
    "# Predicci√≥n\n",
    "y_pred = mi_mlp.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n>>> ACCURACY CONSEGUIDO: {acc*100:.2f}%\")\n",
    "\n",
    "if acc < 0.65:\n",
    "    print(\"‚ö†Ô∏è ALERTA: No llegas al 65%. Sube epochs, baja learning_rate o a√±ade neuronas.\")\n",
    "else:\n",
    "    print(\"‚úÖ OBJETIVO CUMPLIDO (>65%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9a247",
   "metadata": {},
   "source": [
    "#### Modelo definitivo:\n",
    "El modelo seleccionado es una red con arquitectura [X, 64, 32, Y] con learning_rate=0.1 y 10000 epochs porque ha conseguido el mejor equilibrio entre convergencia y precisi√≥n en test (superando el 65%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1abdfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# GR√ÅFICAS (CURVA + MATRIZ DE CONFUSI√ìN)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gr√°fica 1: Curva de P√©rdida (Loss)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(mi_mlp.loss_history)\n",
    "plt.title(\"Curva de Aprendizaje (Loss)\")\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fica 2: Matriz de Confusi√≥n (Bonita)\n",
    "plt.subplot(1, 2, 2)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Matriz de Confusi√≥n\")\n",
    "plt.xlabel(\"Predicci√≥n del Modelo\")\n",
    "plt.ylabel(\"Valor Real\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (Opcional) Informe detallado por clase\n",
    "print(\"\\n--- INFORME DETALLADO ---\")\n",
    "# Si tienes el 'labler' del ejercicio 1, usa target_names para que salgan los nombres reales\n",
    "try:\n",
    "    nombres_clases = labler.classes_.astype(str)\n",
    "    print(classification_report(y_test, y_pred, target_names=nombres_clases))\n",
    "except:\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92073f",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Otros modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac748f5",
   "metadata": {},
   "source": [
    "### MLP SKlearn\n",
    "\n",
    "   | pros | cons | \n",
    "   |---|---|\n",
    "   | tolerancia a ruido | Caja Negra: No sabes por qu√© decide lo que decide. |\n",
    "   | Potencia: Capaz de aprender relaciones muy complejas y no lineales. (lineal y no lineal) | Datos: Necesita muchos datos para brillar (con 300 filas suele sufrir). |\n",
    "   | Escalable: Mejora cuantos m√°s datos le des. | Sensible: Requiere escalar datos (StandardScaler) y ajustar muchos hiperpar√°metros (learning rate, capas...). |\n",
    "\n",
    "√ösala si piden replicar una red cl√°sica o si te piden par√°metros espec√≠ficos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386d3231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entrenando MLP Sklearn (SGD)... ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Entrenando MLP Sklearn (SGD)... ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m mlp_sklearn \u001b[38;5;241m=\u001b[39m MLPClassifier(\n\u001b[0;32m     15\u001b[0m     hidden_layer_sizes\u001b[38;5;241m=\u001b[39mLAYERS,\n\u001b[0;32m     16\u001b[0m     activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Sigmoide\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m           \u001b[38;5;66;03m# Pon True si quieres ver si avanza\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m mlp_sklearn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     25\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m mlp_sklearn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# --- RESULTADOS ---\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURACI√ìN (TOCA AQU√ç SI NO LLEGAS A LA NOTA) ---\n",
    "# Si Accuracy bajo -> Sube capas (ej: (100, 50)) o sube ITERATIONS\n",
    "# Si tarda mucho -> Sube LR_INIT (ej: 0.01)\n",
    "LAYERS = (64, 32)\n",
    "LR_INIT = 0.01   # Con SGD a veces hay que subirlo un poco\n",
    "ITERATIONS = 5000\n",
    "\n",
    "print(\"--- Entrenando MLP Sklearn (SGD)... ---\")\n",
    "mlp_sklearn = MLPClassifier(\n",
    "    hidden_layer_sizes=LAYERS,\n",
    "    activation='logistic',  # Sigmoide\n",
    "    solver='sgd',           # Descenso de gradiente cl√°sico\n",
    "    max_iter=ITERATIONS,\n",
    "    learning_rate_init=LR_INIT,\n",
    "    random_state=42,\n",
    "    verbose=False           # Pon True si quieres ver si avanza\n",
    ")\n",
    "\n",
    "mlp_sklearn.fit(X_train, y_train)\n",
    "y_pred = mlp_sklearn.predict(X_test)\n",
    "\n",
    "# --- RESULTADOS ---\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"‚úÖ Accuracy MLP (SGD): {acc*100:.2f}%\")\n",
    "\n",
    "# Matriz de Confusi√≥n\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Matriz de Confusi√≥n - MLP SGD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5469eb",
   "metadata": {},
   "source": [
    "### MLP Sklearn \"OPTIMIZADO\" (Adam + ReLU)\n",
    "\n",
    "si piden \"M√°ximo rendimiento\" o un accuracy muy alto (>85%). Es la m√°s potente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURACI√ìN PRO ---\n",
    "# ADAM + RELU convergen much√≠simo m√°s r√°pido y mejor.\n",
    "LAYERS = (100, 50) \n",
    "\n",
    "print(\"--- Entrenando MLP Optimizado (Adam + ReLU)... ---\")\n",
    "mlp_opt = MLPClassifier(\n",
    "    hidden_layer_sizes=LAYERS,\n",
    "    activation='relu',      # ¬°CLAVE! ReLU evita desvanecimiento de gradiente\n",
    "    solver='adam',          # ¬°CLAVE! Adam optimiza el learning rate solo\n",
    "    max_iter=5000,\n",
    "    alpha=0.0001,           # Regularizaci√≥n L2 (sube si hay overfitting)\n",
    "    random_state=42,\n",
    "    early_stopping=True     # Para si deja de mejorar (ahorra tiempo)\n",
    ")\n",
    "\n",
    "mlp_opt.fit(X_train, y_train)\n",
    "y_pred = mlp_opt.predict(X_test)\n",
    "\n",
    "# --- RESULTADOS ---\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"üöÄ Accuracy MLP Optimizado: {acc*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Matriz de Confusi√≥n - MLP Adam\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11841086",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "   | pros | cons | \n",
    "   |---|---|\n",
    "   | caja blanca. Simple: Muy f√°cil de entender. | Sensible: El ruido y los datos no escalados lo destrozan. |\n",
    "   | entrenamiento rapido | ejecucion lenta |\n",
    "   | tolerancia a la forma de los datos | costoso en memoria. Maldici√≥n de la dimensi√≥n: Funciona fatal si hay muchas columnas (atributos). |\n",
    "\n",
    "Si tienes muchos datos es lento. Si tienes muchas dimensiones funciona regular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920e659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validacion KNN: 82.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "# n_neighbors: T√≠pico 3, 5, 7. MEJOR IMPARES - CAMBIAR ESTO SI NO LLEGAS \n",
    "# Si el n√∫mero es muy bajo (1) -> Overfitting (ruido).\n",
    "# Si es muy alto (20) -> Underfitting (demasiado suave).\n",
    "K = 5\n",
    "\n",
    "print(f\"--- Entrenando KNN (k={K})... ---\")\n",
    "knn = KNeighborsClassifier(n_neighbors=K)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# --- RESULTADOS ---\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"üìç Accuracy KNN: {acc*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Reds')\n",
    "plt.title(f\"Matriz de Confusi√≥n - KNN ({K})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39e3fc",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "\n",
    "   | pros | cons | \n",
    "   |---|---|\n",
    "   | caja blanca. Totalmente interpretable (sabes qu√© reglas usa). | Inestable: Si cambias un poquito los datos, el √°rbol cambia entero. (sensible al ruido) |\n",
    "   | entrenamiento rapido | simple |\n",
    "   | Feature Importance: Te dice qu√© variables importan. | Tendencia al Overfitting: Si no limitas la profundidad (max_depth), memoriza los datos.|\n",
    "   | Pocos datos: Funciona bien con datasets peque√±os. |  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594211dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validacion DT: 80.90%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURACI√ìN (TOCA AQU√ç) ---\n",
    "# Si Accuracy bajo (Underfitting) -> SUBE max_depth (ej: 15, 20 o None)\n",
    "# Si Overfitting (Train 100% pero Test bajo) -> BAJA max_depth (ej: 5, 8)\n",
    "DEPTH = 10 \n",
    "\n",
    "print(f\"--- Entrenando √Årbol de Decisi√≥n (Depth={DEPTH})... ---\")\n",
    "dt = DecisionTreeClassifier(max_depth=DEPTH, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# --- RESULTADOS ---\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"üå≥ Accuracy Decision Tree: {acc*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Oranges')\n",
    "plt.title(\"Matriz de Confusi√≥n - Decision Tree\")\n",
    "plt.show()\n",
    "\n",
    "# Opcional: Ver importancia de variables\n",
    "# print(\"Importancia:\", dict(zip(final_data.columns[:-1], dt.feature_importances_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25777d0d",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "   | pros | cons | \n",
    "   |---|---|\n",
    "   | El \"Todoterreno\": Casi siempre da el mejor Accuracy sin tocar nada. | Caja Gris/Negra: Pierdes la interpretabilidad sencilla de un solo √°rbol (son 100 √°rboles votando). |\n",
    "   | Robusto: Evita el Overfitting mucho mejor que un √Årbol simple. | Lento: Tarda m√°s en entrenar que un √°rbol simple. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d1fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Validacion RF: 89.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ines\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "# n_estimators: N√∫mero de √°rboles (100 suele bastar, sube a 200 si necesitas m√°s estabilidad)\n",
    "# max_depth: Igual que en el √°rbol, controla la complejidad.\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
    "\n",
    "print(\"--- Entrenando Random Forest... ---\")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# --- RESULTADOS ---\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"üå≤üå≤ Accuracy Random Forest: {acc*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Purples')\n",
    "plt.title(\"Matriz de Confusi√≥n - Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbcc682",
   "metadata": {},
   "source": [
    "# Ejercicio 5.A: Comparativa y Elecci√≥n del Modelo\n",
    "\n",
    " 1. Tabla Resumen de Resultados\n",
    "\n",
    "| Caracter√≠stica | **Modelo A (ej. MLP)** | **Modelo B (ej. Decision Tree)** |\n",
    "| :--- | :--- | :--- |\n",
    "| **Accuracy (Test)** | [ PONER DATO % ] | [ PONER DATO % ] |\n",
    "| **Matriz de Confusi√≥n** | [ ¬øFalla m√°s en Falsos Positivos o Negativos? ] | [ ¬øEst√° equilibrada? ] |\n",
    "| **Tipo de Modelo** | Caja Negra (Opaco) | Caja Blanca (Interpretable) |\n",
    "| **Entrenamiento** | Lento / Requiere muchos datos | R√°pido / Eficiente con pocos datos |\n",
    "\n",
    " 2. Elecci√≥n del Modelo\n",
    "\n",
    "El modelo seleccionado como el m√°s adecuado para este problema es: **[ NOMBRE DEL MODELO GANADOR ]**.\n",
    "\n",
    " 3. Justificaci√≥n (Argumentos)\n",
    "\n",
    "He tomado esta decisi√≥n bas√°ndome en los siguientes tres pilares:\n",
    "\n",
    "1.  **Rendimiento (Accuracy):**\n",
    "    El modelo [GANADOR] presenta un accuracy superior ([X]%) frente al modelo [PERDEDOR] ([Y]%). Adem√°s, observando la matriz de confusi√≥n, comete menos errores cr√≠ticos en la clase [CLASE IMPORTANTE].\n",
    "\n",
    "2.  **Interpretabilidad (Contexto del problema):**\n",
    "    * *(Si gana el √Årbol):* Al tratarse de un problema m√©dico (diagn√≥stico de demencia), es vital entender el \"por qu√©\" de la decisi√≥n. Este modelo nos permite ver qu√© variables (ej. CDR, Edad) son las detonantes, algo que una Red Neuronal no ofrece claramente.\n",
    "    * *(Si gana el MLP):* Aunque perdemos explicabilidad, la complejidad del problema requiere un modelo capaz de detectar patrones no lineales complejos, y la diferencia de precisi√≥n justifica el uso de una \"Caja Negra\".\n",
    "\n",
    "3.  **Idoneidad de los Datos:**\n",
    "    * *(Si el dataset es peque√±o <1000):* Dado que disponemos de pocos datos, un √Årbol de Decisi√≥n o Random Forest suele generalizar mejor, mientras que las Redes Neuronales tienden al Overfitting si no tienen miles de ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2740c69",
   "metadata": {},
   "source": [
    "## Ejercicio 5.B: Metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac4716",
   "metadata": {},
   "source": [
    "Accuracy o Precisi√≥n (tasa de exactitud): \n",
    "$\\Large\\frac{TP+TN}{TP+N+FP+FN} = \\frac{V}{F}$\n",
    "\n",
    "Recall (ratio de positivos reales): $\\Large\\frac{TP}{TP+FN}$\n",
    "\n",
    "Precision (ratio de clasificaciones correctas) : $\\Large\\frac{TP}{TP+FP}$\n",
    "\n",
    "\n",
    "   | ‚Üì Datos predichos | Positive Observed | Negative Observed | ‚Üê Datos reales |\n",
    "   |---|---|---|---|\n",
    "   | Positive Predicted | TP | FP | Precision |\n",
    "   | Negative Predicted | FP | TN |   |\n",
    "   | ‚Üë Datos predichos | Recall |  | |\n",
    "\n",
    "F1Score: $\\Large\\frac{Precision*Recall}{Precision+Recall}$\n",
    "\n",
    "Mide el equilibrio entre el Recall y el Precision entre 0 y 1, 1 seria un clasificador perfecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d575bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Accuracy/Precisi√≥n Custom MLP: 85.39%\n",
      "-> Recall Custom MLP: 85.39%\n",
      "-> Precision Custom MLP: 73.02%\n",
      "-> F1 Score Custom MLP: 71.88%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Matriz de confusion (con una)\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_sklearn, cmap=\"Reds\", colorbar=False)\n",
    "\n",
    "# ACCURACY\n",
    "acc_custom = accuracy_score(y_test, y_pred)\n",
    "print(f\"-> Accuracy/Precisi√≥n Custom MLP: {acc_custom * 100:.2f}%\")\n",
    "\n",
    "# RECALL\n",
    "recall_custom = recall_score(y_test, y_pred, average='micro')\n",
    "print(f\"-> Recall Custom MLP: {recall_custom * 100:.2f}%\")\n",
    "\n",
    "# PRECISION\n",
    "prec_custom = precision_score(y_test, y_pred, average='macro')\n",
    "print(f\"-> Precision Custom MLP: {prec_custom * 100:.2f}%\")\n",
    "\n",
    "# F1 Score\n",
    "f1_custom = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"-> F1 Score Custom MLP: {f1_custom * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c1a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SKLearn\\nAcc: 80.90%')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Matriz de confusion (con varias)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_sklearn, ax=axes[0], cmap=\"Reds\", colorbar=False)\n",
    "axes[0].set_title(f\"MLP\\nAcc: {acc_custom * 100:.2f}%\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_dt, ax=axes[1], cmap=\"Reds\", colorbar=False)\n",
    "axes[1].set_title(f\"SKLearn\\nAcc: {acc_dt * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de02b1",
   "metadata": {},
   "source": [
    "### DIAGNOSTICO\n",
    "\n",
    "   | (coste) | validacion baja | validacion alta | \n",
    "   |---|---|---|\n",
    "   | entrenamiento bajo | precision alta (lo que queremos) | overfitting (overfitting, tmb se puede ir subiendo lambda con cuidado) |\n",
    "   | entrenamiento alto | datos de validacion sesgados (modelo mal) | modelo mal |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ba3d5d",
   "metadata": {},
   "source": [
    "# EJERCICIO 6A. COMPARATIVA de muchos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1. Agrupamos los modelos en un diccionario para iterar f√°cil\n",
    "# Aseg√∫rate de usar los nombres de variables que usaste arriba\n",
    "modelos = {\n",
    "    \"MLP Propio\": mi_mlp,\n",
    "    \"MLP Sklearn\": mlp_sklearn,\n",
    "    \"Random Forest\": rf,\n",
    "    \"KNN\": knn\n",
    "}\n",
    "\n",
    "# Tabla para guardar resultados\n",
    "resultados = []\n",
    "\n",
    "# Configuraci√≥n de los gr√°ficos (2x2)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel() # Aplanar para iterar f√°cil (0, 1, 2, 3)\n",
    "\n",
    "print(\"--- üèÅ COMPARATIVA FINAL DE MODELOS üèÅ ---\")\n",
    "\n",
    "for i, (nombre, modelo) in enumerate(modelos.items()):\n",
    "    # 1. Predecir\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # 2. Calcular M√©tricas\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    resultados.append({\"Modelo\": nombre, \"Accuracy\": acc})\n",
    "    \n",
    "    # 3. Pintar Matriz\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "    axes[i].set_title(f\"{nombre}\\nAcc: {acc*100:.2f}%\")\n",
    "    axes[i].set_xlabel(\"Predicci√≥n\")\n",
    "    axes[i].set_ylabel(\"Real\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Mostrar Tabla de L√≠deres\n",
    "df_res = pd.DataFrame(resultados).sort_values(by=\"Accuracy\", ascending=False)\n",
    "print(\"\\nüèÜ RANKING DE MODELOS:\")\n",
    "print(df_res.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c193b0",
   "metadata": {},
   "source": [
    "#### Elecci√≥n del Modelo Definitivo\n",
    "\n",
    "Tras analizar el rendimiento de los cuatro modelos (MLP Propio, MLP Sklearn, Random Forest y KNN), he decidido quedarme con: [ NOMBRE DEL GANADOR ].\n",
    "\n",
    "Justificaci√≥n de la elecci√≥n:\n",
    "\n",
    "Rendimiento (Accuracy y Matriz de Confusi√≥n): El modelo [GANADOR] ha obtenido la mayor precisi√≥n ([X]%). Observando su matriz de confusi√≥n, es el que mejor distingue entre las clases cr√≠ticas, cometiendo menos errores de tipo Falso Negativo (decir que alguien est√° sano cuando tiene demencia/cardiopat√≠a).\n",
    "\n",
    "Comparativa: Supera al segundo mejor ([SEGUNDO]) en un [Y]%.\n",
    "\n",
    "Estabilidad y Generalizaci√≥n:\n",
    "\n",
    "* (Si gana Random Forest): A diferencia del KNN o el MLP, el Random Forest es m√°s robusto al ruido y al Overfitting gracias a que combina m√∫ltiples √°rboles de decisi√≥n. Esto es crucial dado que nuestro dataset es peque√±o (<1000 filas).\n",
    "\n",
    "* (Si gana MLP Sklearn): Sklearn implementa optimizaciones (Adam) que mi MLP propio no tiene, logrando converger mejor y m√°s r√°pido.\n",
    "\n",
    "Contexto del Problema (M√©dico):\n",
    "\n",
    "* (Si gana RF): Adem√°s del buen rendimiento, el Random Forest nos permite extraer la \"Importancia de las Caracter√≠sticas\" (Feature Importance), algo vital en medicina para explicar qu√© s√≠ntomas son los m√°s alarmantes. El MLP y KNN funcionan como \"cajas negras\".\n",
    "\n",
    "Conclusi√≥n: Aunque [MODELO PERDEDOR] funcionaba r√°pido, su falta de precisi√≥n lo descarta. El [GANADOR] ofrece el mejor equilibrio entre fiabilidad diagn√≥stica y robustez t√©cnica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432f0a6",
   "metadata": {},
   "source": [
    "# EJERCICIO 6B. MLP BINARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db25927",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reemplazamos 'Converted' por 'Demented'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConverted\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDemented\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Verificaci√≥n\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClases tras transformaci√≥n:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Reemplazamos 'Converted' por 'Demented'\n",
    "data['Group'] = data['Group'].replace('Converted', 'Demented')\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(\"Clases tras transformaci√≥n:\", data['Group'].unique())\n",
    "# Deber√≠a salir solo: ['Nondemented' 'Demented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d40ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relimpiamos:\n",
    "\n",
    "import glob as glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "# ---------------- / GESTI√ìN DE NULOS / ------------------- \n",
    "# ----- DIAGNOSTICO\n",
    "# print(\"--- INFO ---\")\n",
    "# print(data.info())\n",
    "# print(\"\\n--- NULOS POR COLUMNA ---\")\n",
    "# print(data.isnull().sum()) # ¬°ESTO ES CRUCIAL!\n",
    "# Si ves una columna con 50% de nulos -> A la lista 'unnecessary_columns'\n",
    "# Si ves una columna con 5% de nulos -> Imputar (media) o Borrar filas\n",
    "\n",
    "# Cuantos datos perderiamos: \n",
    "    # Si se pierden 10-15 filas OPCION A\n",
    "    # si se pierden 50-100 filas OPCION B\n",
    "\n",
    "# ----- QUITAR / MODIFICAR NULOS\n",
    "# OPCI√ìN A : Borrar filas con huecos.\n",
    "# √ösalo si tienes muchos datos (>1000) y pocos huecos.\n",
    "#final_data = data.dropna(how=\"any\")\n",
    "\n",
    "# OPCI√ìN B (Alternativa si tienes pocos datos): IMPUTAR\n",
    "# Si ves que al hacer dropna te quedas con muy pocas filas, usa esto antes de escalar:\n",
    "# data['SES'] = data['SES'].fillna(data['SES'].mean()) # Imputa la media en los huecos de SES (ejemplo num√©rico)\n",
    "# SES: Es un valor socioecon√≥mico (float). Usamos la mediana porque es m√°s robusta.\n",
    "data['SES'] = data['SES'].fillna(data['SES'].median())\n",
    "# MMSE: Es un test mental. Usamos la media (o mediana, ambas valen).\n",
    "data['MMSE'] = data['MMSE'].fillna(data['MMSE'].mean())\n",
    "# Verificamos que ya no quedan nulos\n",
    "#print(\"Nulos restantes:\", data.isnull().sum().sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------- / ATRIBUTOS / ---------------------\n",
    "unnecessary_columns = [\"Subject ID\", \"MRI ID\", \"Hand\"]\n",
    "oneHot_columns = [\"M/F\"]\n",
    "standardScaling_columns = [\"Age\", \"EDUC\", \"SES\", \"MMSE\", \"CDR\", \"eTIV\", \"nWBV\", \"ASF\", \"Visit\", \"MR Delay\"]\n",
    "labeled_columns = [\"Group\"] # SOLUCION\n",
    "\n",
    "solucion = \"Group\" # Nombre de la columna soluci√≥n\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / DROP /  -------------------\n",
    "# Borramos lo que no sirve para limpiar el ruido del dataset.\n",
    "final_data = data.drop(columns=unnecessary_columns) \n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / OHE /  -------------------\n",
    "encoder = OneHotEncoder(sparse_output=False) \n",
    "encoder_final = encoder.fit_transform(data[oneHot_columns])  \n",
    "# Creamos un DF temporal con nombres bonitos (ej: \"M/F_M\", \"M/F_F\")\n",
    "oneHot_df = pd.DataFrame(encoder_final, columns=encoder.get_feature_names_out(oneHot_columns))\n",
    "\n",
    "\n",
    "# ---------------- / SCALER /  -------------------\n",
    "# Transforma los datos para que tengan media 0 y desviaci√≥n t√≠pica 1 (Curva de Gauss).\n",
    "scaler = StandardScaler()\n",
    "scaler_final = scaler.fit_transform(data[standardScaling_columns])\n",
    "df_sc = pd.DataFrame(scaler_final, columns=standardScaling_columns, index=data.index)\n",
    "\n",
    "\n",
    "\n",
    "# ----------------- / LABELED ENCODER / -------------------------   \n",
    "# Convierte \"Demented\" -> 0, \"Nondemented\" -> 1, etc.\n",
    "labler = LabelEncoder()\n",
    "labeled_final = labler.fit_transform(data[labeled_columns].values.ravel()) # o labeled_final = labler.fit_transform(data[labeled_columns])\n",
    "df_lbl = pd.DataFrame(labeled_final, columns=labeled_columns, index=data.index)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# ---------------- / CONCATENAR (SOLUCION AL FINAL) / -------------------\n",
    "# ---- 1. Juntamos las 3 partes: Num√©ricos Escalados + Categ√≥ricos OHE + Soluci√≥n Codificada\n",
    "final_data = pd.concat([df_sc, oneHot_df, df_lbl], axis=1) #axis=1 significa \"pegar columnas a la derecha\"\n",
    "\n",
    "# (Opcional) Si usaras dropna, hazlo aqu√≠ sobre final_data\n",
    "# final_data = final_data.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#final_data.head()\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- / OPCIONAL / -------------------\n",
    "# # Opcional: prints para verificar\n",
    "# print(\"Tama√±o final del dataset:\", final_data.shape)\n",
    "# # para guardarlas en un archivo (opcional)\n",
    "# final_data.to_csv(\"./examen_limpio.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryMLP:\n",
    "    def __init__(self, layers, learning_rate=0.1, epochs=5000):\n",
    "        self.layers = layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.loss_history = []\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        for i in range(len(layers) - 1):\n",
    "            limit = np.sqrt(6 / (layers[i] + layers[i+1]))\n",
    "            w = np.random.uniform(-limit, limit, (layers[i], layers[i+1]))\n",
    "            b = np.zeros((1, layers[i+1]))\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, a):\n",
    "        return a * (1 - a)\n",
    "\n",
    "    # --- CAMBIO 1: Eliminamos Softmax. Usamos Sigmoide tambi√©n al final ---\n",
    "    def forward(self, X):\n",
    "        activations = [X]\n",
    "        input_data = X\n",
    "        \n",
    "        # Capas ocultas\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = np.dot(input_data, self.weights[i]) + self.biases[i]\n",
    "            a = self.sigmoid(z)\n",
    "            activations.append(a)\n",
    "            input_data = a\n",
    "            \n",
    "        # Capa de salida (Ahora usa SIGMOIDE para binario)\n",
    "        z_last = np.dot(input_data, self.weights[-1]) + self.biases[-1]\n",
    "        a_last = self.sigmoid(z_last)  # <--- CAMBIO CLAVE\n",
    "        activations.append(a_last)\n",
    "        \n",
    "        return activations\n",
    "\n",
    "    def backpropagation(self, X, y, activations):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # --- CAMBIO 2: C√°lculo del error simple (a - y) ---\n",
    "        # y ya debe venir con forma (N, 1)\n",
    "        deltas = [activations[-1] - y] \n",
    "        \n",
    "        for i in range(len(self.weights) - 2, -1, -1):\n",
    "            delta_prev = np.dot(deltas[-1], self.weights[i+1].T) * self.sigmoid_derivative(activations[i+1])\n",
    "            deltas.append(delta_prev)\n",
    "        \n",
    "        deltas.reverse()\n",
    "        \n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * (np.dot(activations[i].T, deltas[i]) / m)\n",
    "            self.biases[i] -= self.learning_rate * (np.sum(deltas[i], axis=0, keepdims=True) / m)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # --- CAMBIO 3: No hacemos One-Hot Encoding ---\n",
    "        # Aseguramos que y tenga forma vertical (N, 1)\n",
    "        y = y.reshape(-1, 1) \n",
    "        \n",
    "        print(f\"Entrenando MLP Binario: {self.layers}\")\n",
    "        for epoch in range(self.epochs):\n",
    "            activations = self.forward(X)\n",
    "            self.backpropagation(X, y, activations)\n",
    "            \n",
    "            if epoch % (self.epochs // 10) == 0:\n",
    "                # Loss para clasificaci√≥n binaria\n",
    "                output = activations[-1]\n",
    "                loss = -np.mean(y * np.log(output + 1e-8) + (1 - y) * np.log(1 - output + 1e-8))\n",
    "                self.loss_history.append(loss)\n",
    "                print(f\"   Epoch {epoch}: Loss {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # --- CAMBIO 4: Umbral 0.5 ---\n",
    "        output = self.forward(X)[-1]\n",
    "        return (output > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO\n",
    "# 1. Separar datos (Aseg√∫rate de haber ejecutado la limpieza con el reemplazo de 'Converted')\n",
    "y = final_data[solucion].values.ravel()\n",
    "X = final_data.drop(columns=[solucion]).values\n",
    "\n",
    "# Verificar que solo hay 0 y 1\n",
    "print(\"Clases en y:\", np.unique(y)) \n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 2. Configurar Red BINARIA\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1  # <--- EL ENUNCIADO PIDE 1 √öNICA NEURONA\n",
    "\n",
    "# Estructura: [Entrada, Oculta, Salida(1)]\n",
    "layer_structure = [input_dim, 64, 32, output_dim]\n",
    "\n",
    "# 3. Entrenar\n",
    "binary_model = BinaryMLP(layers=layer_structure, learning_rate=0.1, epochs=10000)\n",
    "binary_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluar\n",
    "y_pred = binary_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n>>> ACCURACY BINARIO: {acc*100:.2f}%\")\n",
    "\n",
    "# Matriz\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Reds')\n",
    "plt.title(\"Matriz de Confusi√≥n (Binaria)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
